\documentclass[a4paper]{article}
\usepackage{tomcmd}
\usepackage{tcolorbox}

\title{\vspace{-2cm}Statistics I Lecture Notes}
\author{Notes by Prof. Matthias Troffaes \\ Typeset in \LaTeX \,by Tom Stoneham}
\date{}

\definecolor{flatblue}{RGB}{84, 109, 229}
\definecolor{flatblack}{RGB}{48, 57, 82}
\definecolor{flatred}{RGB}{225, 95, 65}
\definecolor{flatgreen}{RGB}{33, 140, 116}

\tcbuselibrary{breakable}

\setlength{\tabcolsep}{5pt}
\renewcommand{\arraystretch}{1.5}

\newtcolorbox{definition}[1][]{
    arc=0cm,
    bottomrule at break=0pt,
    breakable,
    colback=white,
    colframe=flatblack,
    title=Definition: #1,
    toprule at break=0pt
}

\newtcolorbox{relq}{
    arc=0cm,
    bottomrule at break=0pt,
    breakable,
    colback=white,
    colframe=flatblue,
    title=Related Questions,
    toprule at break=0pt
}

\newtcolorbox{warn}{
    arc=0cm,
    bottomrule at break=0pt,
    breakable,
    colback=white,
    colframe=flatred,
    title=Warning,
    toprule at break=0pt
}

\newtcolorbox{fread}{
    arc=0cm,
    bottomrule at break=0pt,
    breakable,
    colback=white,
    colframe=flatgreen,
    title=Further Reading,
    toprule at break=0pt
}

\begin{document}

    \maketitle

    \tableofcontents

    \newpage
    \section*{Course Introduction}
    \addcontentsline{toc}{section}{\protect\numberline{}Course Introduction}
        This course is delivered by Matthias Troffaes
        (\href{mailto:matthias.troffaes@durham.ac.uk}
        {\underline{matthias.troffaes@durham.ac.uk}}). Office hours are Mondays,
        from 08:40 - 10:40, in CM304.

        Tutorials will occur once every two weeks, starting in week 12.

        Problems classes occur once every two weeks in the Friday lecture spot,
        starting in week 14.

        Homework will be set every Friday, and is to be handed in to your tutor
        by next Friday at 17:00.

        We're working from a new course. Problem sheets and solutions are
        available on DUO, as are the lecture notes Matthias is working from. Not
        all past exam questions are going to be directly relevant to the course:
        it's mostly the more advanced questions from the problem sheets we
        should use for practice.

        We will follow \textit{Probability \& Statistics}, 2012, 4ed, by DeGroot
        and Schervish, for most lectures, referred to in these notes as [DS12].
        This is available as an e-book
        \href{http://library.dur.ac.uk/record=b2868012~S1}{\underline{on DUO}}.
        For the first few lectures, we will follow \textit{Applied Statistics \&
        Probability for Engineers}, 2003, 3ed, by Montgomery \& Runger, referred
        to as [MR03]. While there is not an e-book freely available, there are a
        number of copies available from the library. Furthermore, the library
        have actually scanned the first two chapters of [MR03], and these are
        available to read via DUO, under ``Library Resources''.

        n.b: Only one person can "borrow" the DS12 ebook at a time, so email the
        library staff if you can't access it.

        Throughout these notes, we will highlight certain information as
        follows:

        \begin{definition}[Introduction]
            \textbf{Definitions} are in dark blue boxes, with the word being
            defined highlighted in bold.
        \end{definition}

        \begin{relq}
            References to related questions on the problem sheets are in light
            blue.
        \end{relq}

        \begin{warn}
            Any warnings/caveats related to a section's content are placed in
            red.
        \end{warn}

        \begin{fread}
            Further reading (from [DS12], [MR03]) will be placed in green.
        \end{fread}

    \newpage
    \section*{Formulae}
    \addcontentsline{toc}{section}{\protect\numberline{}Formulae}
        This isn't in the original lecture notes, but I thought collecting up
        some of the useful formulae from throughout the notes might be a good
        idea. Please message/email me (\href{mailto:tom@sto.neh.am}
        {\underline{tom@sto.neh.am}}) if there's something that should be
        included.

        \subsection*{Tables of Values}
        \addcontentsline{toc}{subsection}{\protect\numberline{}Tables of Values}
            \paragraph{Common Inverse Normal Values:}
                \begin{center}
                    \begin{tabular}{c | c c c c c}
                        $1 - \alpha$ & 0.80 & 0.90 & 0.95 & 0.98 & 0.99 \\
                        \hline
                        $z_{\alpha/2}$ & 1.28 & 1.64 & 1.96 & 2.33 & 2.58
                    \end{tabular}
                \end{center}

        \subsection*{Distributions}
        \addcontentsline{toc}{subsection}{\protect\numberline{}Distributions}
            \paragraph{Binomial}
                \[
                    X \sim \text{Bin}(n, p) \iff p(x) = {n\choose x} p^x (1 -
                    p)^{n - x} \,\fa\, x \in \{0, 1, ..., n\}
                \]
                \[
                    \E(X) = np
                \]
                \[
                    \var(X) = np(1 - p)
                \]

            \paragraph{Poisson}
                \[
                    X \sim \text{Po}(\lambda) \iff p(x) = \frac{\lambda^x
                    e^{-\lambda}}{x!} \,\fa\, x \in \{0, 1, 2, ...\}
                \]
                \[
                    \E(X) = \lambda
                \]
                \[
                    \var(X) = \lambda
                \]

            \paragraph{Normal}
                \[
                    X \sim \mathcal{N}(\mu, \sigma^2) \iff f(x) =
                    \frac{1}{\sigma\sqrt{2\pi}} \exp\left(-\frac{1}{2}\left(
                    \frac{x - \mu}{\sigma}\right)^2\right) \,\fa\, x \in \R
                \]
                \[
                    \E(X) = \mu
                \]
                \[
                    \var(X) = \sigma^2
                \]

            \paragraph{Exponential}
                \[
                    X \sim \text{Exp}(\lambda) \iff f(x) = \lambda e^{-\lambda
                    x} \,\fa\, x \in (0, \infty)
                \]
                \[
                    \E(X) = \frac{1}{\lambda}
                \]
                \[
                    \var(X) = \frac{1}{\lambda^2}
                \]

            \paragraph{Beta}
                \[
                    X \sim \text{Beta}(\alpha, \beta) \iff f(x) =
                    \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)}
                    x^{\alpha - 1}(1 - x)^{\beta - 1} \,\fa\, x \in [0, 1]
                \]
                \[
                    \E(X) = \frac{\alpha}{\alpha + \beta}
                \]
                \[
                    \var(X) = \frac{\alpha\beta}{(\alpha + \beta)^2(\alpha +
                    \beta + 1)}
                \]

            \paragraph{Gamma}
                \[
                    X \sim \text{Gamma}(\alpha, \beta) \iff f(x) =
                    \frac{\beta^\alpha x^{\alpha - 1}e^{-\beta x}}
                    {\Gamma(\alpha)} \,\fa\, x \in (0, \infty)
                \]
                \[
                    \E(X) = \frac{\alpha}{\beta}
                \]
                \[
                    \var(X) = \frac{\alpha}{\beta^2}
                \]

            \paragraph{Lomax}
                \[
                    X \sim \text{Lomax}(\alpha, \beta) \iff f(x) =
                    \frac{\alpha\beta^\alpha}{(x + \beta)^{\alpha + 1}} \,\fa\,
                    x \in (0, \infty)
                \]
                \[
                    \E(X) = \frac{\beta}{\alpha - 1}
                \]
                \[
                    \var(X) = \frac{\alpha\beta^2}{(\alpha - 1)^2(\alpha - 2)}
                \]

        \subsection*{Frequentist Approach}
        \addcontentsline{toc}{subsection}{\protect\numberline{}Frequentist
        Approach}
            \paragraph{Estimators:}
                For any estimator $\widehat T$ of $t(\Theta)$, we have:
                \begin{itemize}
                    \item \textbf{Bias} $:= \E(\widehat T | \theta) - t(\theta)$
                    \item \textbf{Standard error} $:= \sqrt{\var(\widehat T |
                        \theta)}$
                    \item \textbf{Mean square error} $:= \E((\widehat T -
                        t(\theta))^2 | \theta)$
                    \item \textbf{Relation of Mean Square Error, Standard Error,
                        and Basis}:
                        \begin{align*}
                            \text{mean square error} & =
                                (\text{standard error})^2 + (\text{bias})^2 \\
                            \E((\widehat T - t(\theta))^2 | \theta) & = \var(
                                \widehat T | \theta) + (\E(\widehat T | \theta)
                                - t(\theta))^2
                        \end{align*}
                \end{itemize}

            \paragraph{Central Limit Theorem:}
                For an infinite sequences of random variables $X_1, X_2, ...$
                IID conditional on some random variable $\Theta$, with the
                functions $\mu(\theta) := \E(X_i | \theta), \sigma^2(\theta) :=
                \var(X_i | \theta)$, we have that the sample mean $\overline X_n
                := \frac{1}{n} \sum\limits_{i=1}^n X_i$ will follow:

                \[
                    \lim_{n \to \infty} \bb{P}\left(\left.Z_h = \frac{\overline
                    X_n - \mu(\Theta)}{\sigma(\Theta)/\sqrt{n}} \leq z \right|
                    \theta\right) = \Phi(z)
                \]

                where $\Phi$ is the cumulative distribution function of
                $\mathcal{N}(0, 1)$. This leads to the approximate result:

                \[
                    \overline X_n | \theta \sim \mathcal{N}\left(\mu(\theta),
                    \frac{\sigma^2(\theta)}{n}\right)
                \]

            \paragraph{Confidence Interval}
                For $X_1, ..., X_n$ IID conditional on $\Theta$, with $\E(X_i |
                \theta) = \theta, \var(X_i | \theta) = \sigma^2$, the $100 \cdot
                (1 - \alpha)\%$ confidence interval on $\Theta$ is given by:

                \[
                    \left[\overline x_n - z_{\alpha/2}\frac{\sigma}{\sqrt{n}},
                    \overline x_n + z_{\alpha/2} \frac{\sigma}{\sqrt{n}}\right]
                \]

            \paragraph{Frequentist Prediction Interval}
                Assuming that $X_1, ..., X_n$ are IID conditional on $\theta$
                with $X_i | \theta \sim \mathcal{N}(\theta, \sigma^2)$, where
                $\sigma$ is independent of $\theta$, then the $100 \cdot (1 -
                \alpha)\%$ frequentist prediction interval for $X_{n+1}$ is
                given by:

                \[
                    \left[\overline x_n - z_{\alpha/2} \sigma \sqrt{1 +
                    \frac{1}{n}}, \overline x_n + z_{\alpha/2} \sigma \sqrt{1 +
                    \frac{1}{n}}\right]
                \]

        \subsection*{Bayesian Approach}
        \addcontentsline{toc}{subsection}{\protect\numberline{}Bayesian
        Approach}
            \paragraph{Posterior Distribution}
                Assuming $X_1, ..., X_n$ are IID conditional on $\Theta$ with
                assumed pdf $f(x | \theta)$ and prior pdf for $\Theta$ given by
                $f(\theta)$. Then, $\Theta$ has posterior pdf given by:

                \begin{align*}
                    f(\theta | x_1, ..., x_n) & = \frac{f(\theta)
                        \prod\limits_{i=1}^n f(x_i | \theta)}{\int f(\theta')
                        \prod\limits_{i=1}^n f(x_i | \theta') d\theta'} \\
                    & \propind{\theta} f(\theta) \cdot \prod_{i=1}^n f(x_i |
                        \theta)
                \end{align*}

            \paragraph{Likelihood}
                \[
                    f(x_1, ..., x_n | \theta) = \prod_{i=1}^n f(x_i | \theta)
                \]

            \paragraph{Credible Interval}
                For $X_1, ..., X_n$ IID conditional on $\theta$, with $X_i |
                \theta \sim \mathcal{N}(\theta, \sigma^2)$ and posterior
                distribution $\Theta | x_1, ..., x_n \sim \mathcal{N}(\mu_n,
                \sigma_n^2)$, we have that the $100 \cdot (1 - \alpha)\%$
                credible interval for the parameter $\theta$ is given by:

                \[
                    \left[\mu_n - z_{\alpha/2}\sigma_n, \mu_n + z_{\alpha/2}
                    \sigma_n\right]
                \]

            \paragraph{General Posterior Distribution for Normal Sampling}
                Assume $X_i$ are IID conditional on $\Theta$, distributed
                according to $X_i | \theta \sim \mathcal{N}(\theta, \sigma^2)$
                with prior distribution $\Theta \sim \mathcal{N}(\mu_0,
                \sigma_0^2)$, where $\sigma, \sigma_0, \mu_0$ are known
                constants. Then we have:

                \[
                    \mu_n := \frac{\mu_0/\sigma_0^2 + n\overline x_n/\sigma^2}
                    {1/\sigma_0^2 + n/\sigma^2}
                \]
                \[
                    \sigma_n^2 := \left(\frac{1}{\sigma_0^2} +
                    \frac{n}{\sigma^2}\right)^{-1}
                \]
                \[
                    \Theta | x_1, ..., x_n \sim \mathcal{N}(\mu_n, \sigma_n^2)
                \]

            \paragraph{Sequential Updating Theorem}
                \begin{align*}
                    f(\theta | x_1, ..., x_{n+1}) & = \frac{f(\theta | x_1, ...,
                        x_n)f(x_{n+1} | \theta)}{f(x_{n+1} | x_1, ..., x_n)} \\
                    & \propind{\theta} f(\theta | x_1, ..., x_n)f(x_{n+1} |
                        \theta)
                \end{align*}

            \paragraph{Posterior Prediction}
                \[
                    X_{n+1} | x_1, ..., x_n \sim \mathcal{N}(\mu_n, \sigma^2 +
                    \sigma_n^2)
                \]

                Assuming $X_1, ..., X_n$ are IID conditional on $\theta$, and
                $X_i | \theta \sim \mathcal{N}(\theta, \sigma^2)$ with posterior
                distribution $\Theta | x_1, ..., x_n \sim \mathcal{N}(\mu_n,
                \sigma_n^2)$, then the $100 \cdot (1 - \alpha)\%$ posterior
                prediction interval is given by:

                \[
                    \left[\mu_n - z_{\alpha/2} \sqrt{\sigma^2 + \sigma_n^2},
                    \mu_n + z_{\alpha/2} \sqrt{\sigma^2 + \sigma_n^2}\right]
                \]

            \paragraph{Prior Prediction}
                Assuming $X_1, ..., X_n$ are IID conditional on $\theta$, and
                $X_i | \theta \sim \mathcal{N}(\theta, \sigma^2)$ with prior
                distribution $\Theta \sim \mathcal{N}(\mu_0, \sigma_0^2)$, then
                the $100 \cdot (1 - \alpha)\%$ prior prediction interval is
                given by:

                \[
                    \left[\mu_0 - z_{\alpha/2}\sqrt{\sigma^2 + \sigma_0^2},
                    \mu_0 + z_{\alpha/2}\sqrt{\sigma^2 + \sigma_0^2}\right]
                \]

            \paragraph{Bernoulli Distribution with Beta Prior}
                If $X_i | \theta \sim \text{Bernoulli}(\theta)$ IID conditional
                on $\Theta$ with prior $\Theta \sim \text{Beta}(\alpha_0,
                \beta_0)$ for $\alpha_0, \beta_0 > 0$, then:

                \[
                    \Theta | x_1, ..., x_n \sim \text{Beta}\left(\alpha_0 +
                    \sum_{i=1}^n x_i, \beta_0 + n - \sum_{i=1}^n x_i\right)
                \]

            \paragraph{Exponential Distribution with Gamma Prior}
                If $X_i | \theta \sim \text{Exp}(\theta)$ IID conditional on
                $\Theta$ with prior $\Theta \sim \text{Gamma}(\alpha_0,
                \beta_0)$, we have the posterior:

                \[
                    \Theta | x_1, ..., x_n \sim \text{Gamma}\left(\alpha_0 + n,
                    \beta_0 + \sum_{i=1}^n x_i\right)
                \]

                And the posterior predictive:

                \[
                    X_{n+1} | x_1, ..., x_n \sim \text{Lomax}\left(\alpha_0 + n,
                    \beta_0 + \sum_{i=1}^n x_i\right)
                \]

        \subsection*{Bayes Estimators}
        \addcontentsline{toc}{subsection}{\protect\numberline{}Bayes Estimators}
            \paragraph{Standard Loss Functions}
                \begin{itemize}
                    \item \textbf{Squared Error Loss}

                        \[
                            L(\theta, \widehat \theta) := (\theta - \widehat
                            \theta)^2
                        \]
                    \item \textbf{Absolute Error Loss}

                        \[
                            L(\theta, \widehat \theta) := |\theta - \widehat
                            \theta|
                        \]
                \end{itemize}

            \paragraph{Posterior Expected Loss}
                \[
                    \E(L(\Theta, \widehat \theta) | x_1, ..., x_n) :=
                    \int_{-\infty}^\infty L(\theta, \widehat \theta) f(\theta |
                    x_1, ..., x_n) d\theta
                \]

            \paragraph{Bayes Estimate in Squared Error Loss}
                Bayes estimate for $\Theta$ is given by posterior expectation of
                $\Theta$:

                \[
                    \delta(x_1, ..., x_n) = \E(\Theta | x_1, ..., x_n)
                \]

            \paragraph{Bayes Estimate in Absolute Error Loss}
                Bayes estimate for $\Theta$ is posterior median of $\Theta$:

                \[
                    \bb{P}(\Theta \leq \delta(x_1, ..., x_n) | x_1, ..., x_n) =
                    \frac{1}{2}
                \]

    \newpage
    \section{Simple Frequentist Estimation and Prediction}
        \subsection{Statistical Modelling and Inference}
            \begin{fread}
                [MR03, section 7.1]

                [DS12, section 7.1]
            \end{fread}

            Consider the following practical scientific questions:

            \begin{itemize}
                \item By how much will the sea level rise in the next 50 years?
                \item What's the effectiveness of a new cancer treatment?
                \item What's the biological impact of introducing a non-native
                    species to an environment?
                \item How much energy will a new wind farm produce, if built in
                    a certain location?
                \item What is the distribution of dark matter in the universe?
            \end{itemize}

            What do these situations have in common?

            \begin{definition}[Uncertainty{,} Data{,} and Models]
                Each situation involves:

                \begin{itemize}
                    \item \textbf{Uncertainty}: There's no exact answer, due to
                        a lack of knowledge, and due to randomness.
                    \item \textbf{Data}: Empirical observations and expert
                        knowledge.
                    \item \textbf{Model}: Some idea of how the world behaves,
                        and how data are correlated. May be thought of as a
                        specific way of expressing the objective part of expert
                        knowledge. This is based in physics, biology,
                        engineering, etc.
                \end{itemize}
            \end{definition}

            We will use probability theory to tackle these types of question.

            Probability theory involves a number of concepts we will make use
            of:

            \begin{definition}[Probability Theory Concepts]
                The \textbf{possibility space}, notated $\Omega$, is the set of
                all possible outcomes. This can be huge, for example, the set of
                all possible distributions of dark matter; or smaller, like if
                we were to represent sea level rise by a single number.

                We don't normally specify possibility spaces directly, but
                instead focus on \textbf{random variables}. A random variable is
                a \textit{function} from $\Omega \mapsto \R$ (or $\R^k$). This
                can be observed. Random variables will always be denoted by
                capital letters: $X, Y, \Theta, ...$.

                An specific observed value of a random variable will be denoted
                with a lower-case letter: $x, y, \theta, ...$.

                A \textbf{statistical model} consists of an identification of:

                \begin{itemize}
                    \item Relevant random variables (both observable and
                        hypothetically observable) including the data.

                        For example: the expansion coefficient of water, actual
                        rise, global temperature.

                    \item Parameters (both known and unknown), which we may
                        learn about, but not observe directly.

                        For example: The likelihood of recovery following the
                        use of a certain treatment.

                        It's important to note that we may treat uncertain
                        parameters as random variables.

                    \item A joint probability distribution, expressed through
                        probability mass functions (pmfs) and probability
                        density functions (pdfs), on \textit{all} random
                        variables, and possibly on all unknown paramters.
                \end{itemize}
            \end{definition}

            \begin{warn}
                Random variables \textit{only} correspond to observable (or
                \textit{hypothetically} observable) quantities.
            \end{warn}

            \begin{relq}
                Exercises 1 and 2 on the problem sheet give you textual
                descriptions of some scenarios, and ask you to identify the
                statistical model.
            \end{relq}

            \begin{definition}[Statistical inference]
                A \textbf{statistical inference} is a procedure which produces
                a probabilistic statement about any part of a
                statistical model.

                A \textbf{probabilistic statement} is just the probability of an
                event, a mean, a variance, etc; i.e: Anything involving a
                mathematical statement of probability.
            \end{definition}

            \subsubsection{Example: Smartphone Batteries}
                \textit{Consider a smartphone battery production line. Every
                50th battery is destructively tested for ``quality''. Quality,
                here, is just some proxy for the battery lifetime. We're given
                the following data for the quality of the last 10 tested
                batteries:}

                \begin{center}
                    \begin{tabular}{c | c c c c c c c c c c}
                        Battery & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 \\
                        \hline
                        Quality & 90 & 86 & 82 & 77 & 94 & 90 & 87 & 90 & 86 &
                            86
                    \end{tabular}
                \end{center}

                \textit{A battery is deemed faulty if quality is less than 80.
                Identify the relevant statistical model.}

                We first need to identify the relevant random variables:

                \begin{itemize}
                    \item The quality of the tested batteries (the
                        \textit{data}, known): $X_1, ..., X_n$
                    \item The quality of the untested batteries (hypothetically
                        observable, unknown): $X_{n+1}, X_{n+2}, ...$
                \end{itemize}

                $n = 10$ is the sample size.

                We now need to assign some joint distribution. We might
                conjecture the following model, for example:

                The $X_i$ are identically distributed (come from the same
                probability distribution), according to some probability density
                function $f(\cdot | \theta)$, for example, the normal
                distribution, with $\E(X_i | \theta) = \theta, \var(X_i |
                \theta) = 5^2$. This is just an assumption which seems
                reasonable when we look at the data, and is not devised from any
                mathematical process. $\theta$ is an unknown parameter
                representing the mean of $X_i$. $\Theta$ is a random variable
                representing $\theta$.

                Here, $\theta \in \R$, but in general, you can have $\theta \in
                \R^k$ (i.e: multiple parameters).

                \begin{warn}
                    We must assume that $X_i$ are independent
                    \textit{conditional on $\Theta$}.

                    Why can't we assume unconditional independence? Let's assume
                    for now that all variables are discrete, for simplicity.

                    Say that I observe $X_1$ to learn about $X_2$. So we're
                    trying to find:

                    \[
                        \bb{P}(X_2 = x_2 | X_1 = x_1) = \frac{\bb{P}(X_2 = x_2,
                        X_1 = x_1)}{\bb{P}(X_1 = x_1)}
                    \]

                    If we assume the variables are unconditionally independent,
                    we then have:

                    \begin{align*}
                        \bb{P}(X_2 = x_2 | X_1 = x_1) & =
                            \frac{\bb{P}(X_2 = x_2)\bb{P}(X_1 = x_1)}
                            {\bb{P}(X_1 = x_1)} \\
                        & = \bb{P}(X_2 = x_2)
                    \end{align*}

                    So we've learned absolutely nothing about $X_2$!

                    If, on the other hand, we assume conditional independence on
                    $\Theta$, we have:

                    \begin{align*}
                        \bb{P}(X_2 = x_2 | X_1 = x_1) & = \sum_\theta \bb{P}(X_2
                            = x_2 | X_1 = x_1, \Theta = \theta) \cdot
                            \bb{P}(\Theta = \theta | X_1 = x_1) \\
                        & = \sum_\theta \bb{P}(X_2 = x_2 | \Theta = \theta)
                            \cdot \bb{P}(\Theta = \theta | X_1 = x_1) \\
                        & = \sum_\theta \bb{P}(X_2 = x_2 | \Theta = \theta)
                            \cdot \frac{\bb{P}(X_1 = x_1 | \Theta = \theta)
                            \bb{P}(\Theta = \theta)}{\bb{P}(X_1 = x_1} \\
                        & \neq \bb{P}(X_2 = x_2) \quad \textit{(generally)}
                    \end{align*}

                    So we can learn about $X_2$ given the value of $X_1$! This
                    is actually the \textit{only} way to enable learning, by
                    DeFinetti's representation theorem.
                \end{warn}

            \subsubsection{Estimation and Prediction}
                Typically, we perform statistical inference about either unknown
                parameters, such as $\Theta$, or about future observations, such
                as $X_{n+1}$.

                \begin{definition}[Estimation{,} Prediction]
                    \textbf{Estimation} specifically refers to statistical
                    inference about unknown parameters, like $\Theta$.

                    \textbf{Prediction} refers to statistical inference about
                    future observations.
                \end{definition}

        \subsection{Point Estimation}
            \begin{fread}
                [MR03, section 7.2]
            \end{fread}

            Let's return to the battery example. Consider the sample mean:

            \[
                \overline X_n := \frac{1}{n} \sum_{i=1}^n X_i
            \]

            This would be a good choice to estimate $\theta$, because:

            \begin{align*}
                \E(\overline X_n | \theta) & = \frac{1}{n} \sum_{i = 1}^n \E(X_i
                    | \theta) \\
                & = \frac{1}{n}n\theta \\
                & = \theta
            \end{align*}

            We can also use the sample mean to estimate the variance:

            \begin{align*}
                \var(\overline X_n | \theta) & = \frac{1}{n^2} \sum_{i = 1}^n
                    \var(X_i | \theta) \\
                & = \frac{1}{n^2} n 5^2 \\
                & = \frac{5^2}{n}
            \end{align*}

            Note that $\var(\overline X_n | \theta) \to 0$ as $n \to \infty$.
            So, we might wish to use $\overline X_n$ as an approximation for
            $\Theta$.

            \begin{definition}[Statistic{,} Estimator{,} Point Estimate]
                A \textbf{statistic} is a real-valued function of the data, for
                example, $\overline X_n$.

                An \textbf{estimator}, $\widehat T$, is a statistic which is
                meant to approximate some real-valued function, $t(\Theta)$, of
                the parameters. Remember that the parameters are random
                variables, so a function of a parameter is also a random
                variable. Usually, $t(\Theta)$ is just the identity function. We
                write $\widehat \Theta$ for an estimator of $\Theta$.

                A \textbf{point estimate}, $\widehat t$ for $t(\Theta)$ is just
                a specific realisation of an estimator $\widehat T$ for
                $t(\Theta)$ after observing the data (the actual value of
                $\widehat T$). We write $\widehat \theta$ for a point-estimate
                of $\Theta$.
            \end{definition}

            In our battery example, $\widehat \Theta = \overline X_{10}$ is an
            estimator for $\Theta$. $\widehat \theta = \frac{1}{10} (90 + 86 +
            ...) = 86.8$ is a point estimate of $\Theta$.

            \subsubsection{Properties of Estimators}
                \begin{definition}[Bias{,} Errors]
                    For any estimator $\widehat T$ of $t(\Theta)$, we define:

                    \begin{itemize}
                        \item \textbf{Bias} $:= \E(\widehat T | \theta) -
                            t(\theta)$

                            An estimator with zero bias $\fa\, \theta$ is called
                            \textbf{unbiased}.

                            We saw that, for the sample mean, the conditional
                            expectation is equal to the value we want to
                            estimate, so we would say this estimator is
                            unbiased.

                        \item \textbf{Standard error} $:= \sqrt{\var(\widehat T
                            | \theta)}$.

                            We can think of this as how much an estimator will
                            vary, its conditional standard deviation.

                            We want for an estimator to have a low standard
                            error.

                        \item \textbf{Mean square error} $:= \E((\widehat T -
                            t(\theta))^2 | \theta)$

                            This is what we (usually) \textit{really} want to
                            minimise for a good estimator. We prefer estimators
                            with a low mean square error.
                    \end{itemize}
                \end{definition}

            \subsubsection{Theorem: Relation of Mean Square Error, Standard
            Error, and Bias}
                \begin{align*}
                    \text{mean square error} & = (\text{standard error})^2 +
                        (\text{bias})^2 \\
                    \E((\widehat T - t(\theta))^2 | \theta) & = \var(\widehat T
                        | \theta) + (\E(\hat T | \theta) - t(\theta))^2
                \end{align*}

                \begin{relq}
                    Exercise 3 involves proving this relation. The solution is
                    on DUO if you really want to be sure about the proof.
                \end{relq}

                This theorem is important because, since we're trying to
                minimise mean square error, we might actually prefer a biased
                estimator, provided its standard error is lower.

                \incfig{./12mse.pdf_tex}

                In this case, for example, we might choose to use the clearly
                biased estimator $\widehat\Theta_2$, since its variance being so
                low may lead to a lower mean square error than
                $\widehat\Theta_1$.

            \subsubsection{Theorem: Sample Mean Is Minimum Variance Unbiased
            Estimator}
                Consider some sequence of random variables $X_1, X_2, ...$, with
                $X_i | \theta \sim \mathcal{N}(\theta, \sigma^2)$ where the
                $X_i$ are independent, identically distributed (IID) conditional
                on $\Theta$ and $\sigma > 0$ is some known constant. Then,
                $\overline X_n$ is the minimum variance unbiased estimator of
                $\Theta$ (in essence: the sample mean is the best estimator we
                can construct of $\Theta$).

                \begin{relq}
                    The proof of this theorem is not given, but a related
                    (simpler) proof is required for exercises 3 to 7.
                \end{relq}

            \subsubsection{Bias and Error in the Battery Example}
                In the battery example, we showed:

                \[
                    \E(\overline X_n | \theta) = \theta
                \]
                \[
                    \var(\overline X_n | \theta) \frac{5^2}{n}
                \]

                So $\overline X_n$ is an unbiased estimator of $\Theta$.

                $\overline X_n$ has standard error $\frac{5}{\sqrt{n}}$, so the
                mean square error is $\frac{5^2}{n}$.

        \subsection{Interval Estimation}
            \begin{fread}
                [MR03, section 8.1, 8.2.1]
            \end{fread}

            \subsubsection{Central Limit Theorem (CLT)}
                This is a key result from probability theory.

                Consider an infinite sequence of random variables, $X_1, X_2,
                ...$. We will assume they are IID conditional on some random
                variable $\Theta$.

                We will define the following functions:

                \[
                    \mu(\theta) := \E(X_i | \theta)
                \]
                \[
                    \sigma^2(\theta) := \var(X_i | \theta)
                \]

                Note that neither $\mu$ nor $\theta$ depend on $i$ due to the
                IID assumption.

                We will further define the following random variables:

                \[
                    \overline X_n := \frac{1}{n} \sum_{i=1}^n X_i
                \]
                \[
                    Z_n := \frac{\overline X_n - \mu(\Theta)}{\sigma(\Theta) /
                    \sqrt{n}} \quad \textit{(the standardised sample mean)}
                \]

                Then, $\fa z \in \R$, and all possible values of $\theta$, we
                have:

                \[
                    \lim_{n \to \infty} \bb{P}(Z_n \leq z | \theta) = \Phi(z)
                \]

                where $\Phi$ is the cumulative distribution function of
                $\mathcal{N}(0, 1)$.

                The practical implication of this theorem is that, for large
                $n$, we have the approximate result:

                \[
                    \overline X_n | \theta \sim \mathcal{N}\left(\mu(\theta),
                    \frac{\sigma^2(\theta)}{n}\right)
                \]

                This approximation improves with a larger value of $n$, or as
                the distribution of $X_i | \theta$ is closer to the normal.

            \subsubsection{Application of CLT to Battery Example}
                In our battery example, $\mu(\theta) = \theta, \sigma^2(\theta)
                = 5^2$. So, $\overline X_{10} | \theta \sim
                \mathcal{N}\left(\theta, \frac{5^2}{10}\right)$ approximately.

                Can we exploit the CLT to make stronger probabilistic statements
                about $\overline X_{10}$ and $\Theta$?

                Let's assume the conditions of the central limit theorem, with
                $\mu(\theta) = \theta$ and $\sigma^2(\theta) = \sigma^2$ (i.e:
                $\sigma^2$ is constant). Fix any $\alpha \in [0, 1]$ and let
                $z_{\alpha/2} := \Phi^{-1}\left(1 - \frac{\alpha}{2}\right)$

                \incfig{./13clt.pdf_tex}

                By the CLT:

                \[
                    \bb{P}(|Z_n| \leq z_{\alpha/2} | \theta) = 1 - \alpha
                \]

                By the definition of $Z_n$:

                \[
                    \bb{P}\left(\left|\frac{\overline X_n - \theta}
                    {\sigma/\sqrt{n}}\right| \leq z_{\alpha/2} | \theta\right) =
                    1 - \alpha
                \]

                or equivalently:

                \[
                    \bb{P}\left(\overline X_n - z_{\alpha/2} \frac{\sigma}
                    {\sqrt{n}} \leq \theta \leq \overline X_n + z_{\alpha/2}
                    \frac{\sigma}{\sqrt{n}}|\theta\right) = 1 - \alpha
                \]

                This is a \textbf{confidence interval}, which we will define
                after a caveat.

                \begin{warn}
                    Note that, here, the $\theta$ on the left is a constant, as
                    we're conditional on $\theta$, not a random variable, and
                    $X_n$ is a random variable. So, if we have a value for the
                    sample mean, we can construct the interval.

                    This does \textit{not} say that the probability that
                    $\theta$ lies in this specific interval is $1 - \alpha$.

                    See section 1.3.3 for more information on the issues with
                    thinking about confidence intervals like this.
                \end{warn}

                \begin{definition}[Confidence Interval]
                    Assume $X_1, X_2, ..., X_n$ are IID, conditional on
                    $\Theta$, and assume that $\E(X_i | \theta) = \theta$,
                    $\var(X_i | \theta) = \sigma^2 > 0$ is known, and constant
                    independent of $\theta$. Then, $\fa \alpha \in [0, 1]$:

                    \[
                        \left[\overline x_n - z_{\alpha/2}\frac{\sigma}
                        {\sqrt{n}}, \overline x_n + z_{\alpha/2}
                        \frac{\sigma}{\sqrt{n}}\right]
                    \]

                    is a $100 \cdot (1 - \alpha)\%$ \textbf{confidence interval}
                    on $\Theta$.
                \end{definition}

                Common values for $z_{\alpha/2}$:

                \begin{center}
                    \begin{tabular}{c | c c c c c}
                        $1 - \alpha$ & 0.80 & 0.90 & 0.95 & 0.98 & 0.99 \\
                        \hline
                        $z_{\alpha/2}$ & 1.28 & 1.64 & 1.96 & 2.33 & 2.58
                    \end{tabular}
                \end{center}

                Now that we've defined what a confidence interval means, we
                should return to the battery example. In this example, $n = 10,
                \overline x_{10} = 86.8, \sigma = 5$. For a 95\% confidence
                interval, we need to calculate:

                \[
                    \overline x_n - 1.96 \frac{\sigma}{\sqrt{n}} = 83.7
                \]
                \[
                    \overline x_n + 1.96 \frac{\sigma}{\sqrt{n}} = 89.9
                \]

                So the 95\% confidence interval for $\Theta$ is given by
                $[83.7, 89.9]$.

                \begin{relq}
                    Problem 11 is highly relevant here, and is the closest so
                    far to an actual exam question we would expect to see.

                    Problem 9 also relies on confidence intervals and would be
                    useful to attempt.
                \end{relq}

            \subsubsection{What Does a Confidence Interval Mean?}
                In the battery example, does $[83.7, 89.9]$ really capture the
                uncertainty of $\Theta$? In particular, does the event $\Theta
                \in [83.7, 89.9]$ have probability 0.95? \textit{No!}

                \[
                    \bb{P}\left(\overline X_n - z_{\alpha/2}
                    \frac{\sigma}{\sqrt{n}} \leq \theta \leq \overline X_n +
                    z_{\alpha/2} \frac{\sigma}{\sqrt{n}}|\theta\right) = 1 -
                    \alpha
                \]

                The probability in this equation, which we used to define a
                confidence interval, is \textit{conditional on knowing $\Theta =
                \theta$}. This isn't really what we want! We want it to be
                conditional on $\overline X_n = \overline x_n$.

                Instead, we \textit{only} know that $\fa \theta \in \R$, the
                following event:

                \[
                    \theta \in \left[\overline X_n - 1.96
                    \frac{\sigma}{\sqrt{n}}, \overline X_n + 1.96
                    \frac{\sigma}{\sqrt{n}}\right]
                \]

                has probability 0.95, conditional on $\Theta = \theta$.

                We used the distribution of $\overline X_n$ conditional on
                $\Theta = \theta$. We \textit{really} want the distribution of
                $\Theta$ conditional on $X_1 = x_1, ..., X_n = x_n$.

                How can we do that? We'll use Bayes's theorem in a later section.
                However, the computations are much harder, and we must be able
                to treat $\Theta$ as a random variable, which we've managed to
                avoid while thinking about confidence intervals.

        \subsection{Interval Prediction}
            \begin{fread}
                [MR03, section 8.6]
            \end{fread}

            Let's think about the battery example again. What can we say about
            the quality level of an untested battery, $X_{n+1}$? In other words,
            having observed $X_1, ..., X_n$, what can we say about $X_{n+1}$?

            In prediction, we can no longer rely on the central limit theorem as
            we did in estimation, and must instead make another assumption about
            the distribution of $X_n$. So, we will assume normality, again, IID
            conditional on $\theta$:

            \[
                X_i | \theta \sim \mathcal{N}(\theta, \sigma^2)
            \]

            We then have:

            \begin{align*}
                \E(X_{n + 1} - \overline X_n | \theta) & = \E(X_{n + 1} |
                    \theta) - \E(\overline X_n | \theta) \\
                & = \theta - \theta \\
                & = 0
            \end{align*}
            \begin{align*}
                \var(X_{n + 1} - \overline X_n | \theta) & = \var(X_{n + 1} |
                    \theta) + \var(\overline X_n | \theta) & \textit{(by IID of
                    $X_1, ..., X_{n+1}$)} \\
                & = \sigma^2 + \frac{\sigma^2}{n} \\
                & = \sigma^2 \left(1 + \frac{1}{n}\right)
            \end{align*}

            Note that $X_{n + 1}$ is distributed normally, and each $X_i$ is
            normal, so the sample mean (a sum of normals) will also be normally
            distributed, and the difference $X_{n + 1} - \overline X_n$ will
            also have a normal distribution as follows:

            \[
                X_{n + 1} - \overline X_n \sim \mathcal{N}\left(0,
                \sigma^2\left(1 + \frac{1}{n}\right)\right)
            \]

            and consequently, via a similar calculation to how we analysed
            confidence intervals, we have:

            \[
                \bb{P}\left(\left.\overline X_n - z_{\alpha/2} \sigma\sqrt{1 +
                \frac{1}{n}} \leq X_{n + 1} \leq \overline X_{n} + z_{\alpha/2}
                \sigma\sqrt{1 + \frac{1}{n}} \right| \theta\right) = 1 - \alpha
            \]

            \begin{definition}[Frequentist Prediction Interval]
                Assume $X_1, X_2, ..., X_n$ are IID, conditional on $\theta$,
                and assume that $X_i | \theta \sim \mathcal{N} (\theta,
                \sigma^2)$, where $\sigma$ is independent of $\theta$. Then,
                $\fa \alpha \in [0, 1]$:

                \[
                    \left[\overline x_n - z_{\alpha/2}\sigma\sqrt{1 +
                    \frac{1}{n}}, \,\overline x_n + z_{\alpha/2} \sigma\sqrt{1 +
                    \frac{1}{n}}\right]
                \]

                is a $100 \cdot (1 - \alpha)\%$ \textbf{frequentist prediction
                interval} for $X_{n + 1}$.
            \end{definition}

            \begin{warn}
                Similar concerns to those involved in interval estimation apply:
                We used the distribution of $\overline X_n$ and $X_{n + 1}$
                conditional on $\Theta = \theta$, but we actually want the
                distribution of $X_{n + 1}$ conditional on the data: $X_1 = x_1,
                ..., X_n = x_n$!
            \end{warn}

            \subsubsection{Interval Prediction in the Battery Example}
                We have $n = 10, \overline X_n = 86.8, \sigma = 5$, so we
                attain:

                \[
                    \overline x_n - 1.96 \sigma \sqrt{1 + \frac{1}{n}} = 76.5
                \]
                \[
                    \overline x_n + 1.96 \sigma \sqrt{1 + \frac{1}{n}} = 97.1
                \]

                Recall that a battery was designated faulty if its quality was
                less than 80, so the 95\% prediction interval includes values
                less than this threshold. As such, we'd expect to see more
                failures than we might be comfortable with, and we might wish to
                redesign the battery production process.

                The interval $[76.5, 97.1]$ is a 95\% frequentist prediction
                interval for $X_{n + 1}$.


        \subsection{Parameters as Random Variables}
            \begin{fread}
                [DS12, section 7.1]
            \end{fread}

            For what we've done so far, we have avoided having to consider
            $\Theta$ as a random variable, because we only used $\bb{P}(\cdot |
            \theta)$, which we could consider as a distribution parametrised by
            $\theta$. This may be notated (and in textbooks, commonly is
            notated) as $\bb{P}_\theta(\cdot)$, or even just $\bb{P}(\cdot)$.

            Doing this is appropriate if we only want to make probability
            statements indexed by $\theta$. However, this is very limiting.

            If we want to make more advanced probability statements, can we
            treat $\Theta$ as a random variable? \textit{Yes}, provided that
            $\Theta$ is (hypothetically) observable.

            How can we make $\Theta$ observable? Consider, for instance, the
            example in which we observed the quality of batteries. By the strong
            rule of large numbers, we have:

            \[
                \bb{P}\left(\Theta = \lim_{n \to \infty} \frac{1}{n}
                \sum_{i=1}^n X_i\right) = 1
            \]

            This just means that as we take a very large value of $n$ for our
            sample size, we expect the sample average to converge to $\Theta$.

            So in this specific example, we can treat $\Theta$ as if it were the
            observable quantity $\frac{1}{n} \sum\limits_{i=1}^n X_i$ for very
            large $n$. This limit construction is possible for a very wide range
            of practical statistical models (and, in particular, every model
            that we'll encounter in first year).

    \newpage
    \section{Prior and Posterior Distributions}
        \subsection{Prior Distributions}
            \begin{fread}
                [DS12, section 7.2]
            \end{fread}

            \begin{definition}[Prior PDF/PMF]
                The \textbf{prior pdf or pmf} of a \textit{parameter} $\Theta$
                is the pdf/pmf of $\Theta$ in advance of observing any data.
                This can be used to quantify uncertainty in advance of observing
                actual values. Mathematically, this is the
                \textit{unconditional} marginal pdf/pmf of $\Theta$.

                We don't have prior pdf/pmfs for all random variables, only
                parameters.
            \end{definition}

            \subsubsection{Examples}

                Let's go back to the battery example we looked at throughout
                section 1, which we modelled as follows:

                \[
                    X_i | \theta \sim \mathcal{N}(\theta, 5^2)
                \]

                Prior to seeing the data, the manager supposes that the
                parameter $\Theta$ is normally distributed, with mean 90 and
                standard deviation 10. So we have:

                \[
                    \Theta \sim \mathcal{N}(90, 10^2), \implies f(\theta) =
                    \frac{1}{10\sqrt{2\pi}} \exp{\left(-\frac{1}{2}\left(
                    \frac{\theta - 90}{10}\right)^2\right)}
                \]

                This is the prior pdf for $\Theta$. \textit{It is unconditional
                on any $X_i$.}

                \begin{warn}
                    The point of a prior pdf/pmf is that it is entirely
                    unconditional on any $X_i$. You \textit{cannot} use any data
                    parameters observed in a sample to determine the prior
                    distribution.
                \end{warn}

                Let's move on to another example. Consider the outcome $X$ of a
                coin toss. $X | \theta \sim \text{Bin}(\theta, 1)$, where $X =
                1$ represent heads, and $X = 0$ tails and either:

                \begin{itemize}
                    \item The coin is fair: $\theta = \frac{1}{2}$,
                    \item Or the coin has two heads: $\theta = 1$
                \end{itemize}

                Before we do any experimentation, we'll make a judgement about
                whether we think the coin is fair or not. Let's suppose we know
                the coin is fair with 80\% probability. We can express this
                information using a probability mass function:

                \[
                    p(\theta) = \begin{cases}0.8, & \theta = \frac{1}{2} \\ 0.2,
                    & \theta = 1\end{cases}
                \]

                This is a prior pmf on $\Theta$.

                We now have two examples of prior pdf/pmfs, and the distribution
                of data. Upon observing data, can we update our potential
                pdf/pmfs to quantify the uncertainty in $\Theta$?

        \subsection{Posterior Distribution and Likelihood}
            \begin{definition}[Posterior Distribution]
                The \textbf{posterior distribution} of a \textit{parameter}
                $\Theta$ is the pdf or pmf of $\Theta$ after observing the data
                (i.e: the \textit{conditional} pdf/pmf of $\Theta$ given $X_1 =
                x_1, X_2 = x_2, ..., X_n = x_n$, or any other observed random
                variables comprising the data, although in this course the
                observed random vars will always be in this form).
            \end{definition}

            Usually, the posterior distribution is calculated via Bayes's
            theorem.

            \subsubsection{Posterior Distribution for the Coin Toss Example}
                Consider again the coin toss problem, and say that we observe
                heads: $X = 1$. This provides some evidence that it might be
                more likely that there are two heads.

                Then, by Bayes's theorem, we have:

                \begin{align*}
                    \bb{P}\left(\left.\Theta = \frac{1}{2} \right| X = 1\right)
                        & = \frac{\bb{P}\left(X = 1 | \Theta =
                        \frac{1}{2}\right) \bb{P}\left(\Theta =
                        \frac{1}{2}\right)}{\bb{P}\left(X = 1 | \Theta =
                        \frac{1}{2}\right)\bb{P}\left(\Theta = \frac{1}{2}
                        \right) + \bb{P}(X = 1 | \Theta = 1)\bb{P}(\Theta = 1)}
                        \\
                    & = \frac{\frac{1}{2} \cdot 0.8}{\frac{1}{2} \cdot 0.8 + 1
                        \cdot 0.2} \\
                    & = \frac{2}{3}
                \end{align*}

                We could also evaluate the probability that $\Theta$ is $1$ by
                performing the same calculation to attain $\bb{P}(\theta = 1 |
                X = 1) = \frac{1}{3}$. So the probability that the coin is
                biased has increased, which makes intuitive sense.

                It's also worth checking for yourself that $\bb{P}\left(\Theta =
                \frac{1}{2} | x = 0\right) = 1$.

            \subsubsection{Theorem: Posterior Distribution in General}
                Assume $X_1, ..., X_n$ are IID, conditional on $\Theta$, with
                pdf $f(x | \theta)$ and $\Theta$ has a prior pdf $f(\theta)$.
                Then, $\Theta$ has posterior pdf given by:

                \[
                    f(\theta | x_1, ..., x_n) = \frac{f(\theta)
                    \prod\limits_{i=1}^n f(x_i | \theta)}{\int f(\theta ')
                    \prod\limits_{i=1}^n f(x_i | \theta') d\theta'}
                \]

                $\theta'$ is just a dummy variable over which we're integrating
                here.

                If we instead have a probability mass function for the data, the
                formula is exactly the same, we just replace $f(x_i | \theta)$
                with $p(x_i | \theta)$.

                If the prior distribution is a pmf rather than a pdf, replace
                $f(\theta)$ with $p(\theta)$, replace $f(\theta | x_1, ...,
                x_n)$ with $p(\theta | x_1, ..., x_n)$, and note that the
                integral $\int ... d\theta'$ becomes a sum
                $\sum\limits_{\theta'}$.

                \paragraph{Proof}
                    Given a model as above with IID observations and a prior
                    pdf, we can write down the full joint density for the model
                    by the definition of conditional density:

                    \begin{align*}
                        f(x_1, ..., x_n, \theta) & = f(x_1, ..., x_n | \theta)
                            \cdot f(\theta) \\
                        & = f(\theta) \cdot \prod_{i=1}^n f(x_i | \theta) &
                            \textit{(by IID of $X_i$ cond on $\Theta$)}
                    \end{align*}

                    Also, we have that the integral of this product over
                    $\theta$ will give us the joint distribution of the $X_i$s,
                    by the partition theorem:

                    \begin{align*}
                        f(x_1, ..., x_n) & = \int f(x_1, ..., x_n, \theta') d
                            \theta' \\
                        & = \int f(\theta') \cdot \prod_{i=1}^n f(x_i | \theta')
                            d\theta'
                    \end{align*}

                    Finally, by the definition of conditional density, we have
                    that:

                    \begin{align*}
                        f(\theta | x_1, ..., x_n) & = \frac{f(x_1, ..., x_n,
                            \theta)}{f(x_1, ..., x_n)} \\
                        & = \frac{f(\theta) \prod\limits_{i=1}^n f(x_i |
                            \theta)}{\int f(\theta ') \prod\limits_{i=1}^n f(x_i
                            | \theta') d\theta'} & \square
                    \end{align*}

                    The proof is very similar if we use pmfs instead.

                \paragraph{Tackling the Integral}
                    The tricky part of using this theorem to calculate posterior
                    distributions tends to be evaluating the integral in the
                    denominator. It is useful to note, however, that it only
                    depends on the data $x_1, ..., x_n$, not the parameter
                    $\theta$. It only acts to normalise the numerator (to make
                    sure the integral of the density equals $1$).

                    We can exploit this fact to write the following:

                    \[
                        f(\theta | x_1, ..., x_n) \propind{\theta}
                        f(\theta) \cdot \prod_{i=1}^n f(x_i | \theta)
                    \]

                    \begin{warn}
                        The symbol $\propind{\theta}$ means ``is equal to, up to
                        a factor independent of $\theta$''. So the constant of
                        proportionality (the \textit{normalisation constant})
                        can depend on anything
                        except $\theta$.
                    \end{warn}

                    \begin{definition}[Likeliness Function{,} Likelihood]
                        We define the \textbf{likeliness function} or
                        \textbf{likelihood} to be the conditional pdf/pmf of
                        the data given the parameter:

                        \[
                            f(x_1, ..., x_n | \theta) = \prod_{i=1}^n f(x_i |
                            \theta)
                        \]

                        where the $X_i$ are IID are conditional on $\Theta$.

                        So, the posterior is proportional to the prior
                        distribution, multiplied by the likelihood.
                    \end{definition}

            \subsubsection{Assorted Lemmata}
                For working with normal priors and likelihoods, the following
                results are very useful:

                \paragraph{Lemma 2.2.3(a)}
                    Let's say we have the following:

                    \[
                        f(y | z) \propind{y} \exp\left(-\frac{1}{2}\left(
                        \frac{y - \mu(z)}{\sigma(z)}\right)^2\right)
                    \]

                    This is equivalent to saying:

                    \[
                        Y | z \sim \mathcal{N}(\mu(z), \sigma^2(z))
                    \]

                    The proof of this is trivial given the definition of the
                    normal distribution.

                \paragraph{Lemma 2.2.3(b)}
                    Let's say we have a sum of the following form:

                    \[
                        \sum_{i=1}^n a_i (\theta - b_i)^2
                    \]

                    We then have the following:

                    \begin{align*}
                        \sum_{i=1}^n a_i (\theta - b_i)^2 & = \left(\sum_{i=1}^n
                            a_i\right) \cdot \left(\theta -
                            \frac{\sum\limits_{i=1}^na_ib_i}{\sum\limits_{i=1}^n
                            a_i}\right)^2 + ... & \textit{(all other terms are
                            independent of $\theta$)}
                    \end{align*}

                \paragraph{Lemma 2.2.3(c)}
                    If we just have two terms in the previous sum:

                    \begin{align*}
                        a_1(\theta - b_1)^2 + a_2(\theta - b_2)^2 & =
                            (a_1 + a_2) \cdot \left(\theta - \frac{a_1b_1 +
                            a_2b_2}{a_1 + a_2}\right)^2 + \left(\frac{1}{a_1} +
                            \frac{1}{a_2}\right)^{-1} \cdot (b_1 - b_2)^2
                    \end{align*}

            \subsubsection{Posterior Distribution for the Battery Example}
                We'll again assume that the distribution of quality is normal,
                IID conditional on $\theta$:

                \[
                    X_i | \theta \sim \mathcal{N}(\theta, 5^2)
                \]

                What is the likelihood (up to $\propind{\theta}$)?

                \begin{align*}
                    f(x_1, ..., x_n | \theta) & = \prod_{i=1}^n f(x_i | \theta)
                        \\
                    & = \prod_{i = 1}^n \frac{1}{5\sqrt{2\pi}} \exp\left(-
                        \frac{1}{2} \left(\frac{x_i - \theta}{5}\right)^2\right)
                        \\
                    & \propind{\theta} \exp\left(-\frac{1}{2}\sum_{i=1}^n \left(
                        \frac{1}{5^2} (\theta - x_i)^2\right)\right) \\
                    & = \exp\left(-\frac{1}{2}\left(\frac{n}{5^2} \left(\theta -
                        \frac{\sum_{i=1}^n \frac{x_i}{5^2}}{n/5^2}\right)^2 + F
                        \right)\right)& \textit{(by lemma 2.2.3(b), $F$
                        independent of $\theta$)} \\
                    & \propind{\theta} \exp\left(-\frac{n}{2 \cdot 5^2}\left(
                        \theta - \overline x_n\right)^2\right) \\
                    & = \exp\left(-\frac{10}{2 \cdot 5^2}(\theta - 86.8)^2
                        \right)
                \end{align*}

                So, up to a factor independent of $\theta$, our likelihood only
                depends on the data through $\overline x_n$. Consequently, so
                will the posterior! Therefore, for this model, $\overline X_n$
                is called a \textbf{sufficient statistic}: We don't need to know
                the full data to make inferences about $\Theta$, we only need to
                know the sample mean $\overline X_n$!

                In order to find a posterior distribution, we need to suppose a
                prior distribution for $\Theta$, which is based on expert
                knowledge. Let's say an expert gives the following prior
                distribution:

                \[
                    \Theta \sim \mathcal{N}(90, 10^2)
                \]

                What is the posterior density for $\Theta$?

                \begin{align*}
                    f(\theta | x_1, ..., x_n) & \propind{\theta} f(\theta)
                        f(x_1, ..., x_n | \theta) \\
                    & \propind{\theta} \exp\left(-\frac{1}{2}\left(\frac{\theta
                        - 90}{10}\right)^2\right) \cdot \exp\left(-\frac{n}{2
                        \cdot 5^2}(\theta - \bar x_n)^2\right) \\
                    & = \exp\left(-\frac{1}{2}\left[\left(\frac{\theta - 90}{10}
                        \right)^2 + \frac{n}{5^2}(\theta - \bar x_n)^2\right]
                        \right)
                        \\
                    & = \exp\left(-\frac{1}{2}\left(\frac{1}{10^2} +
                        \frac{n}{5^2}\right)\left(\theta - \frac{\frac{90}{10^2}
                        + \frac{n \bar x_n}{5^2}}{\frac{1}{10^2} +
                        \frac{n}{5^2}}\right)^2\right) \\
                    & = \exp\left(-\frac{1}{2}\left(\frac{1}{1.56}\right)^2
                        \left(\theta - \frac{\frac{90}{10^2} + \frac{n \bar x_n}
                        {5^2}}{\frac{1}{10^2} + \frac{n}{5^2}}\right)^2\right)
                        \\
                    & = \exp\left(-\frac{1}{2}\left(\frac{1}{1.56}\right)^2
                        \left(\theta - 86.9\right)^2\right) \\
                \end{align*}
                \[
                    \implies \Theta | x_1, ..., x_n \sim \mathcal{N}(86.9,
                    1.56^2)
                \]

                \begin{definition}[Credible Interval]
                    An interval $[l, u]$ is called a $100 \cdot (1 - \alpha)\%$
                    \textbf{credible interval} for $t(\Theta)$ given $X_1 = x_1,
                    X_2 = x_2, ..., X_n = x_n$ when the posterior probability of
                    $t(\Theta) \in [l, u]$ is $1 - \alpha$.

                    \[
                        \bb{P}(l \leq t(\Theta) \leq u | X_1 = x_1, ..., X_n =
                        x_n) = 1 - \alpha
                    \]

                    $X_1, ..., X_n$ could be any other variable that comprise
                    the data.

                    For $X_1, ..., X_n$ IID conditional on $\theta$, and assume
                    $X_i | \theta \sim \mathcal{N}(\theta, \sigma^2)$ with
                    posterior distribution $\Theta | x_1, ..., x_n \sim
                    \mathcal{N}(\mu_n, \sigma_n^2)$, we have that the $100 \cdot
                    (1 - \alpha)$ credible interval for the parameter $\theta$
                    is given by:

                    \[
                        [\mu_n - z_{\alpha/2}\sigma_n, \mu_n +
                        z_{\alpha/2}\sigma_n]
                    \]
                \end{definition}

                We can now construct genuinely useful probability intervals for
                $\Theta$ conditional on the data!

                \[
                    \bb{P}(86.9 - 1.96 \cdot 1.56 \leq \Theta \leq 86.9 + 1.96
                    \cdot 1.56 | x_1, ..., x_n) = 0.95
                \]

                $[83.8, 90.0]$ is a 95\% credible interval on $\theta$.

                \begin{warn}
                    We should note that the 95\% credible interval for $\theta$,
                    $[83.8, 90.0]$, is very similar to the 95\% confidence
                    interval, $[83.7, 89.9]$, obtained earlier from the same
                    data. This is not a coincidence as we will see later, but we
                    \textit{must} keep in mind the different interpretations of
                    the two intervals.
                \end{warn}

                To bring into sharper relief the difference between a confidence
                interval and a credible interval, let's consider what happens
                when we have a more informative prior, say:

                \[
                    \Theta \sim \mathcal{N}(90, 0.1^2)
                \]

                We have the same calculations as before, leaving us with:

                \[
                    \Theta | x_1, ..., x_n \sim \mathcal{N}(89.99, 0.0998^2)
                \]

                This is almost unchanged from the prior, due to the extremely
                low variance of the prior reflecting strong prior knowledge in
                the value of $\Theta \approx 90$.

            \subsubsection{Theorem: General Case for Normal Sampling}
                Consider a general situation as before, with $\sigma, \sigma_0$
                and $\mu_0$ known constants, $X_i$ IID conditional on $\Theta$,
                distributed as follows:

                \[
                    X_i | \theta \sim \mathcal{N}(\theta, \sigma^2)
                \]

                and prior distribution:

                \[
                    \Theta \sim \mathcal{N}(\mu_0, \sigma_0^2)
                \]

                Then:

                \[
                    \Theta | x_1, ..., x_n \sim \mathcal{N}(\mu_n, \sigma^2_n)
                \]

                where:

                \[
                    \mu_n := \frac{\mu_0/\sigma_0^2 + n\bar x_n/\sigma^2}
                    {1/\sigma_0^2 + n/\sigma^2}
                \]
                \[
                    \sigma_n^2 := \left(\frac{1}{\sigma_0^2} +
                    \frac{n}{\sigma^2}\right)^{-1}
                \]

                These formulae should probably just be memorised.

                The proof is similar to the battery example given earlier.

                So if $\frac{1}{\sigma_0^2} \ll \frac{n}{\sigma^2}$, then the
                data will drive the posterior, and the credible interval will be
                more similar to the confidence interval.

                Whereas, if $\frac{1}{\sigma_0^2} \gg \frac{n}{\sigma^2}$, then
                the prior will drive the posterior.

                If $\frac{1}{\sigma_0^2} \approx \frac{n}{\sigma^2}$, then both
                the data and the prior will influence the posterior.

                \begin{warn}
                    Thinking about the prior/posterior in this way really makes
                    it clear why $\sigma_0, \mu_0$ (the std. dev. and mean for
                    the prior) should not be based on the data! They must
                    reflect the uncertainty about $\theta$ as if you had not
                    seen the data.
                \end{warn}

        \subsection{Sequential Updating and Prediction}
            Let's look at the posterior after a single observation, $X_1 = x_1$:

            \[
                f(\theta | x_1) \propind{\theta} f(\theta)f(x_1 | \theta)
            \]

            Now after the second observation, $X_2 = x_2$:

            \begin{align*}
                f(\theta | x_1, x_2) &\propind{\theta} f(\theta) f(x_1 | \theta)
                    f(x_2 | \theta) \\
                & \propind{\theta} f(\theta | x_1) f(x_2 | \theta)
            \end{align*}

            So, we can treat the posterior after our first observation as our
            prior for the posterior following the second! Similarly, after the
            third observation, $X_3 = x_3$:

            \begin{align*}
                f(\theta | x_1, x_2, x_3) & \propind{\theta} f(\theta) f(x_1 |
                    \theta) f(x_2 | \theta) f(x_3 | \theta) \\
                & \propind{\theta} f(\theta | x_1, x_2) f(x_3 | \theta)
            \end{align*}

            \subsubsection{The Sequential Updating Theorem}
                \[
                    f(\theta | x_1, ..., x_{n+1}) \propind{\theta} f(\theta |
                    x_1, ..., x_n) f(x_{n+1} | \theta)
                \]

                We can use the posterior after $n$ observations as a prior for
                updating with observation $n + 1$.

                The constant of proportionality has a special meaning,
                encapsulated in the following theorem.

            \subsubsection{Theorem: Predictive Distribution from Sequential
            Updates}
                \[
                    f(\theta | x_1, ..., x_{n + 1}) = \frac{f(\theta | x_1, ...,
                    x_n)f(x_{n+1} | \theta)}{f(x_{n+1} | x_1, ..., x_n)}
                \]

                So the constant of proportionality is the predictive
                distribution! We will use this to predict the next observation
                given the previous observations.

                \paragraph{Proof}
                    \begin{align*}
                        f(\theta | x_1, ..., x_{n+1}) f(x_{n+1} | x_1, ..., x_n)
                            & = f(\theta, x_{n+1} | x_1, ..., x_n) \\
                        & = f(x_{n+1} | \theta, x_1, ..., x_n) f(\theta | x_1,
                            ..., x_n) \\
                        & = f(x_{n+1} | \theta) f(\theta | x_1, ..., x_n) &
                            \textit{(by IID on $\theta$)} \quad \square
                    \end{align*}

                \begin{definition}[Prior Predictive PDF]
                    We define the \textbf{prior predictive pdf} to be
                    $f(x_{n+1})$, and the \textbf{posterior predictive pdf} to
                    be $f(x_{n+1} | x_1, ..., x_n)$.

                    We use the prior predictive pdf to predict $X_{n+1}$ before
                    having seen the data, and the posterior predictive to
                    predict $X_{n + 1}$ after having seen the data.
                \end{definition}

            \subsubsection{Prediction in the Battery Example}
                Consider again the battery example with $X_i$ IID conditional on
                $\Theta$ distributed according to:

                \[
                    X_i | \theta \sim \mathcal{N}(\theta, 5^2)
                \]

                with the prior distribution for $\Theta$ given by:

                \[
                    \Theta \sim \mathcal{N}(90, 10^2)
                \]

                Let's find $f(x_{n+1} | x_1, ..., x_n)$ for our specific data.
                One way to do so is to use theorem 2.3.2, and evaluate up to
                $\propind{x_{n+1}}$:

                \[
                    f(x_{n+1} | x_1, ..., x_n) = \frac{f(\theta | x_1, ..., x_n)
                    f(x_{n+1} | \theta)}{f(\theta | x_1, ..., x_{n+1})}
                \]

                Note that, since the left hand side is not a function of
                $\theta$, you should either see that factors of $\theta$ on the
                right hand side cancel out, or just fix a value of $\theta$
                where $f(\theta | x_1, ..., x_{n + 1}) > 0$.

                \[
                    f(x_{n+1} | x_1, ..., x_n) \propind{x_{n+1}}
                        \frac{f(x_{n+1} | \theta)}{f(\theta |x_1, ..., x_{n+1})}
                \]

                Alternatively, we could also evaluate, up to
                $\propind{x_{n+1}}$:

                $$
                    f(x_{n+1}|x_1, ..., x_n) = \int f(x_{n+1}|\theta)f(\theta|
                    x_1, ..., x_n) d\theta
                $$

                So we have:

                \begin{align*}
                    f(x_{n + 1} | x_1, ..., x_n) & = \int_{-\infty}^\infty
                        \frac{1}{\sigma\sqrt{2\pi}} \exp{-\frac{1}{2}\left(
                        \frac{x_{n+1} - \theta}{\sigma}\right)^2} \cdot
                        \frac{1}{\sigma_n\sqrt{2\pi}} \exp{-\frac{1}{2}\left(
                        \frac{\theta - \mu_n}{\sigma_n}\right)^2} d\theta \\
                    & \propind{x_{n+1}} \int_{-\infty}^\infty \exp{-\frac{1}{2}
                        \left(\left(\frac{x_{n+1} - \theta}{\sigma}\right)^2 +
                        \left(\frac{\theta - \mu_n}{\sigma_n}\right)^2\right)}
                        d\theta \\
                    & = \int_{-\infty}^\infty \exp{-\frac{1}{2}\left[\left(
                        \frac{1}{\sigma^2} + \frac{1}{\sigma_n^2}\right)\left(
                        \theta - \frac{x_{n+1}/\sigma^2 + \mu_n/\sigma_n^2}
                        {1/\sigma^2 + 1/\sigma_n^2}\right)^2 + (\sigma^2 +
                        \sigma_n^2)^{-1}(x_{n+1} - \mu_n)^2\right]} d\theta \\
                    & = \exp{\left(-\frac{1}{2}\frac{(x_{n+1} - \mu_n)^2}{
                        \sigma^2 + \sigma_n^2}\right)} \cdot \int_{-\infty}
                        ^\infty \exp{-\frac{1}{2}\left(\frac{\theta - \mu_{n+1}}
                        {\sigma_{n+1}}\right)^2} d\theta \\
                    & \propind{x_{n + 1}} \exp{-\frac{1}{2} \frac{1}{\sigma^2 +
                        \sigma_n^2} (x_{n+1} - \mu_n)^2}
                \end{align*}

                $$
                    \implies X_{n+1} | x_1, ..., x_n \sim \mathcal{N}(\mu_n,
                    \sigma^2 + \sigma_n^2)
                $$

                \begin{definition}[Posterior and Prior Prediction Intervals]
                    Assume $X_1, X_2, ..., X_n$ are IID conditional on $\theta$,
                    and assume $X_i | \theta \sim \mathcal{N}(\theta, \sigma^2
                    )$, with posterior distribution $\Theta | x_1, ..., x_n \sim
                    \mathcal{N}(\mu_n, \sigma_n^2)$.Then, $\fa \alpha \in [0,
                    1]$:

                    \[
                        \left[\mu_n - z_{\alpha/2} \sqrt{\sigma^2 + \sigma_n^2},
                        \mu_n + z_{\alpha/2} \sqrt{\sigma^2 + \sigma_n^2}\right]
                    \]

                    is a $100 \cdot (1 - \alpha)\%$ \textbf{posterior prediction
                    interval} for $X_{n + 1}$.

                    The $100 \cdot (1 - \alpha)\%$ \textbf{prior prediction
                    interval} given a prior distribution $\Theta \sim
                    \mathcal{N}(\mu_0, \sigma_0^2)$ is given by:

                    \[
                        \left[\mu_0 - z_{\alpha/2} \sqrt{\sigma^2 + \sigma_0^2},
                        \mu_0 + z_{\alpha/2} \sqrt{\sigma^2 + \sigma_0^2}\right]
                    \]
                \end{definition}

                Substituting our specific data, we have $\mu_n = 86.9, \sqrt{
                \sigma^2 + \sigma_n^2} = 5.24$. So:

                $$
                    \bb{P}(86.9 - 1.96 \cdot 5.24 \leq X_{n+1} \leq 86.9 + 1.96
                    \cdot 5.24 | x_1, ..., x_n) = 0.95
                $$

                and the 95\% posterior prediction interval for $X_{n+1}$ is:

                $$
                    [76.6, 97.2]
                $$

                This is very similar to the 95\% frequentist prediction interval
                $[76.5, 97.1]$ for the same data obtained earlier.

                If, instead, we had a prior pdf for $\Theta$ such that:

                $$
                    \Theta \sim \mathcal{N}(90, 0.1^2)
                $$

                we would have $\mu_n = 89.99, \sigma_n = 0.0998$, as seen
                earlier, so the 95\% posterior prediction interval is:

                $$
                    [89.99 - 1.96\sqrt{5^2 + 0.0998^2}, 89.99 + 1.96\sqrt{5^2 +
                    0.0998^2}] = [80.188, 99.792]
                $$

                Due to the very low variance in the prior pdf, we would expect
                this prediction interval to be almost identical to the 95\%
                prior prediction interval. This would be:

                $$
                    [90 - 1.96 \sqrt{5^2 + 0.1}, 90 + 1.96\sqrt{5^2 + 0.1}] =
                    [80.198, 99.802]
                $$

                \begin{relq}
                    These questions are probably appropriate for the whole of
                    section 2.

                    [DS12, section 7.2, exercises 1, 2, 3, 4, 5, 6, 7, 10, 11]
                \end{relq}

    \newpage
    \section*{Aside: Summary of Sections 1 and 2}
    \addcontentsline{toc}{section}{\protect\numberline{}Aside: Summary of
    Sections 1 and 2}
        \subsection*{Frequentist Method}
        \addcontentsline{toc}{subsection}{\protect\numberline{}Frequentist
        Method}
            \begin{itemize}
                \item Needs a likelihood, given by:

                    $$
                        \prod_{i=1}^n f(x_i | \theta)
                    $$

                \item We constructed confidence intervals, conditioned on the
                    parameter $\theta$:

                    $$
                        \bb{P}(L \leq \theta \leq U | \theta) = 1 - \alpha
                    $$

                    where $L, U$ are functions of the data, e.g: $\overline X_n
                    \pm z_{\alpha/2}, ...$

                \item We don't have a sense of having a distribution for a
                    predictive quantity based on the data in the frequentist
                    approach.

                \item We constructed frequentist prediction intervals:

                    $$
                        \bb{P}(L \leq X_{n+1} \leq U | \theta) = 1 - \alpha
                    $$
            \end{itemize}

        \subsection*{Bayesian Method}
        \addcontentsline{toc}{subsection}{\protect\numberline{}Bayesian Method}
            \begin{itemize}
                \item Needs a posterior $\propto$ prior $\times$ likelihood:

                    $$
                        f_{\alpha_0}(\theta | x_1, ..., x_n) \propind{\theta}
                        f_{\alpha_0}(\theta) \prod_{i=1}^n f(x_i | \theta)
                    $$

                    Here, $\alpha_0$ is a hyper-parameter, like $\mu_0,
                    \sigma_0$: It's a parameter that determines the distribution
                    of other parameters.

                \item We constructed credible intervals, conditioned on the
                    data:

                    $$
                        \bb{P}(l \leq \Theta \leq u | x_1, ..., x_n) = 1 -
                        \alpha
                    $$

                    where $l, u$ are functions of the data and the
                    hyper-parameters (so $\alpha_0, x_1, ..., x_n$).

                \item We looked at the posterior predictive distribution:

                    $$
                        f_{\alpha_0}(x_{n+1} | x_1, ..., x_n) \propind{x_{n+1}}
                        \frac{f(x_{n+1}| \theta)}{f_{\alpha_0}(\theta | x_1,
                        ..., x_{n+1})}
                    $$

                \item We constructed posterior prediction intervals, also
                    conditioned on the data:

                    $$
                        \bb{P}(l \leq X_{n+1} \leq u | x_1, ..., x_n) = 1 -
                        \alpha
                    $$

                \item We looked at the prior predictive distribution:

                    $$
                        f_{\alpha_0}(x_{n+1}) \propind{x_{n+1}} \frac{f(x_{n+1}
                        | \theta)}{f_{\alpha_0}(\theta)}
                    $$

                \item We constructed prior predictive intervals:

                    $$
                        \bb{P}(l' \leq X_{n+1} \leq u') = 1 - \alpha
                    $$

                    where $l', u'$ are functions of $\alpha_0$ only.
            \end{itemize}

    \newpage
    \section{Conjugate Distributions}
        \subsection{Sampling from a Normal with Known Variance}
            We saw that, in the context of the battery example, if $X_i | \theta
            \sim \mathcal{N}(\theta, \sigma^2)$ IID conditional on $\Theta$, and
            $\Theta \sim \mathcal{N}(\mu_0, \sigma_0)$, then the posterior
            distribution for $\Theta$ is also normal:

            $$
                \Theta | x_1, ..., x_n \sim \mathcal{N}(\mu_n, \sigma_n^2)
            $$

            with simple formulae for $\mu_n, \sigma_n$ as functions of $\mu_0,
            \sigma_0, x_1, ..., x_n$ to update from the prior to the posterior.

            The property that the posterior is from the same class of
            distribution as the prior is not unique to this scenario!

        \subsection{Sampling from a Bernoulli Distribution}
            \subsubsection{Example: Clinical Trial}
                150 patients are randomly selected, and receive different
                treatments for depression: Imipramine (treatment 1), lithium
                carbonate (treatment 2), a combination of the two (treatment 3),
                or a placebo (treatment 4). The following table shows the number
                of patients who suffered a relapse within three years:

                \begin{center}
                    \begin{tabular}{c | c c c c | c}
                        Treatment & 1 & 2 & 3 & 4 & Total \\
                        \hline
                        Relapse & 18 & 13 & 22 & 24 & 77 \\
                        No relapse & 22 & 25 & 16 & 10 & 73 \\
                        \hline
                        Total & 40 & 38 & 38 & 34 & 150
                    \end{tabular}
                \end{center}

                For now, we'll just focus on treatment 1, and try to apply
                Bayesian methods in order to make statistical inferences. Let
                $\Theta$ be the proportion of patients from the general
                population suffering from depression who do not relapse under
                this treatment.

                The first step is to identify the statistical model: We will
                define the random variable as follows:

                $$
                    X_i = \begin{cases}0, & \text{if patient relapses} \\
                    1 & \text{if patient does not relapse}\end{cases}
                $$
                $$
                    X_i | \theta \sim \text{Bernoulli}(\theta)
                $$

                (so $\bb{P}(X_i = 1 | \theta) = \theta, \bb{P}(X_i = 0 | \theta)
                = 1 - \theta$).

                We will assume the following prior distribution for $\Theta$:

                $$
                    \Theta \sim \text{Beta}(\alpha, \beta), \quad \alpha > 0,
                    \beta > 0
                $$

                \begin{definition}[Beta Distribution]
                    Let $\alpha > 0, \beta > 0$. We say that $\theta$ follows a
                    \textbf{Beta distribution}, $\text{Beta}(\alpha, \beta)$,
                    when $\Theta$ has the following pdf:

                    $$
                        f(\theta) := \begin{cases}\frac{\Gamma(\alpha + \beta)}
                        {\Gamma(\alpha)\Gamma(\beta)} \cdot \theta^{\alpha - 1}
                        \cdot (1 - \theta)^{\beta - 1}, & 0 \leq \theta \leq 1
                        \\ 0, & \text{otherwise}\end{cases}
                    $$

                    N.b: $\frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma
                    (\beta)}$ is the normalisation constant.

                    For the beta distribution, we have the following
                    expressions:

                    \[
                        \E(\Theta) = \frac{\alpha}{\alpha + \beta}
                    \]
                    \[
                        \var(\Theta) = \frac{\alpha\beta}{(\alpha + \beta)^2(
                        \alpha + \beta + 1)}
                    \]

                    You don't need to remember these formulae, they'll be given
                    to you if you have to use them in an exam setting.

                    $\Gamma$ is the \textbf{gamma function}. We don't need to
                    know much about it, other than that for $z > 0$, we have
                    $\Gamma(z) > 0$. Again, if we need to use its properties in
                    an exam, we will be given them. There is not a closed form
                    expression for its entire domain.
                \end{definition}

                Returning to the clinical trial example, let's look at the
                likelihood. As this is a discrete case, we'll have a pmf rather
                than a pdf, which by the IID cond on $\Theta$ assumption, is
                given by:

                \begin{align*}
                    p(x_1, ..., x_n | \theta) &= \prod_{i=1}^n \theta^{x_i} (1 -
                        \theta)^{1 - x_i} \\
                    & = \theta^y (1 - \theta)^{n - y}, \quad \left(
                        \textit{where } y := \sum_{i=1}^n x_i\right)
                \end{align*}

                So $Y_i = \sum\limits_{n=1}^n X_i$ is a sufficient statistic,
                and since we have the data, we have its value.

                Now let's find the posterior distribution:

                \begin{align*}
                    f(\theta | x_i, ..., x_n) & \propind{\theta} f(\theta)
                        p(x_1, ..., x_n | \theta) \\
                    & \propind{\theta} \begin{cases}\theta^{\alpha + y -1} \cdot
                        (1 - \theta)^{\beta + n - y - 1}, & \theta \in [0, 1] \\
                        0, & \text{otherwise}\end{cases} \\
                \end{align*}

                So the posterior distribution must be a $\text{Beta}(\alpha + y,
                \beta + n - y)$ distribution!

            \subsubsection{Theorem}
                If $X_i | \theta \sim \text{Bernoulli}(\theta)$ IID conditional
                on $\Theta$, and $\Theta \sim \text{Beta}(\alpha_0, \beta_0)$
                for some constants $\alpha_0, \beta_0 > 0$ then we've shown that
                $\Theta | x_1, ..., x_n \sim \text{Beta}(\alpha_n, \beta_n)$
                where, with $y := \sum\limits_{i=1}^n x_i$, we have:

                \[
                    \alpha_n := \alpha_0 + y
                \]
                \[
                    \beta_n := \beta_0 + n - y
                \]

            \subsubsection{Application of Bayesian Stats to Clinical Trial}
                In the clinical trial above, if $\Theta \sim
                \text{Beta}(1, 1) \, (= \mathcal{U}(0, 1))$, then for the first
                treatment, since $n = 40, y = 22$, we have that:

                \[
                    \Theta | x_1, ..., x_n \sim \text{Beta}(1 + 22, 1 + 40 - 22)
                    = \text{Beta}(23, 19)
                \]

                For the posterior expectation/variance, we have:

                \[
                    \E(\Theta | x_1, ..., x_n) = \frac{1 + 22}{1 + 22 + 1 + 40 -
                    22} = \frac{23}{42} = 0.45
                \]
                \[
                    \var(\Theta | x_1, ..., x_n) = \frac{23 \cdot 19}{42^2 \cdot
                    43} = 0.076^2
                \]

                For comparison with the prior, we had $\E(\Theta) = \frac{1}{2},
                \var(\Theta) = 0.29^2$. So the uncertainty has really decreased.

                For the credible interval, unfortunately, there's no closed form
                when using the beta distribution.

        \subsection{Conjugate Families and Hyper-Parameters}
            \begin{definition}[Conjugate Families]
                Assume we have data $X_i$, IID conditional on the parameter
                $\Theta$ with pdf $f(x | \theta)$, or pmf $p(x | \theta)$. Let
                $f_\alpha(\theta)$ represent a family of densities for $\Theta$,
                indexed by the \textit{hyper-parameter} $\alpha \in \mathcal{A}
                \subseteq \R^k$. Then this family is said to be a
                \textbf{conjugate family of priors} for sampling from $f(x |
                \theta)$ if $\fa \alpha_0 \in \mathcal{A}$, and all $n \in \N$,
                and all possible samples $x_1, ..., x_n$, then $\ex \alpha_n \in
                \mathcal{A}$ such that:

                \[
                    f(\theta) = f_{\alpha_0}(\theta) \implies f(\theta | x_1,
                    ..., x_n) = f_{\alpha_n}(\theta)
                \]

                i.e: Whenever the prior belongs to the family, then so does the
                posterior.
            \end{definition}

            The benefit of using a conjugate family is that \textit{updating the
            distribution is reduced to updating just the hyper-parameters!}

            Let's consider, for example, the case using the normal distribution.
            $\mathcal{N}(\mu_0, \sigma_0^2)$, with hyperparameters $\mu_0
            \in \R, \sigma_0 > 0$, is a conjugate family for $X_i | \theta \sim
            \mathcal{N}(\theta, \sigma^2)$, assuming that $\sigma$ is known.

            \[
                \mu_n := \frac{\mu_0/\sigma_0^2 + n\overline x_n/\sigma^2}{1/
                \sigma_0^2 + n/\sigma^2}
            \]
            \[
                \sigma_n^2 := \left(\frac{1}{\sigma_0^2} + \frac{n}{\sigma^2}
                \right)^{-1}
            \]

            Now considering a beta distribution, $\text{Beta}(\alpha_0, \beta_0)
            $ with hyper-parameters $\alpha_0, \beta_0 > 0$, we see that this
            forms a conjugate family for $X_i | \theta \sim
            \text{Bernoulli}(\theta)$, with:

            \[
                \alpha_n := \alpha_0 + \sum\limits_{i=1}^n x_i
            \]
            \[
                \beta_n := \beta_0 + n - \sum\limits_{i=1}^n x_i
            \]


        \subsection{Sampling from an Exponential Distribution}
            \begin{fread}
                [DS12]
            \end{fread}

            \subsubsection{Example: Lifetimes of Electrical Components}
                Consider a company selling electrical components. Each component
                is assumed to fail with probability $\theta dt$ in any time
                interval $[t, t + dt]$ for small values of $dt$, where $\theta$
                is an unknown parameter. So the component lifetimes $X_1, X_2,
                ...$ are exponentially distributed, as follows:

                \[
                    X_i | \theta \sim \text{Exp}(\theta)
                \]

                in which $\theta$ is called the rate parameter. The pdf for this
                distribution is given by:

                \[
                    f(x_i | \theta) = \begin{cases}\theta \exp{(-\theta x_i)}, &
                    x_i \geq 0 \\ 0, & \text{otherwise}\end{cases}
                \]

                We make the usual assumption that the $X_i$ are IID conditional
                on $\Theta$.

                A priori, the company judges that $\E(\Theta) = 0.5,
                \var(\Theta) = 0.5^2$. We then observe: $X_1 = 3,
                X_2 = 1.5, X_3 = 2.1$. What can we say about future failures?

                We need to identify:

                \begin{enumerate}
                    \item A family of conjugate priors for this case (i.e: the
                        case of sampling from an exponential distribution)
                    \item The posterior pdf of $\Theta$
                    \item The posterior \textit{predictive} pdf of $\Theta$
                \end{enumerate}

                \begin{definition}[Gamma Distribution]
                    We say that $\Theta \sim \text{Gamma}(\alpha, \beta)$ for
                    $\alpha, \beta > 0$ if the pdf is given by:

                    \[
                        f(\theta) = \begin{cases}\frac{\beta^\alpha}
                        {\Gamma(\alpha)} \theta^{\alpha - 1} e^{-\beta\theta},
                        & \theta \geq 0 \\ 0, & \text{otherwise}\end{cases}
                    \]

                    This is the family of \textbf{gamma distributions}.

                    For a gamma distribution, we have the following results:

                    \begin{itemize}
                        \item $\E(\Theta) = \frac{\alpha}{\beta}$
                        \item $\var(\Theta) = \frac{\alpha}{\beta^2}$
                        \item If $\alpha = 1$, then we have $\text{Gamma}(1,
                            \beta) = \text{Exp}(\beta)$
                    \end{itemize}
                \end{definition}

                In this example, if $\Theta \sim \text{Gamma}(\alpha_0,
                \beta_0)$ for some known constants $\alpha_0, \beta_0 > 0$, then
                for $\theta \geq 0$, the posterior distribution follows:

                \begin{align*}
                    f(\theta | x_1, ..., x_n) & \propind{\theta} f(\theta)
                        \prod_{i=1}^n f(x_i | \theta) \\
                    & \propind{\theta} \theta^{\alpha_0 - 1} e^{-\beta_0\theta}
                        \prod_{i=1}^n \theta e^{-\theta x_i} \\
                    & = \theta^{\alpha_0 + n - 1} \exp\left(-\left(\beta_0 +
                        \sum_{i=1}^n x_i\right)\theta\right)
                \end{align*}

                This is a $\text{Gamma}(\alpha_n, \beta_n)$ pdf, with:

                \[
                    \alpha_n := \alpha_0 + n
                \]
                \[
                    \beta_n := \beta_0 + \sum_{i=1}^n x_i
                \]

                So, the family of Gamma distributions is \textit{conjugate for
                exponential sampling}.

                In this example, we need that $\E(\Theta) =
                \frac{\alpha_0}{\beta_0} = \frac{1}{2}$, and $\var(\Theta) =
                \frac{\alpha_0}{\beta_0^2} = \frac{1}{4}$, so we can very easily
                see that $\alpha_0 = 1, \beta_0 = 2$.

                The posterior distribution will be a $\text{Gamma}(\alpha_n,
                \beta_n)$ distribution, with:

                \[
                    \alpha_n = \alpha_0 + n = 1 + 3 = 4
                \]
                \[
                    \beta_n = \beta_0 + \sum_{i=1}^n x_i = 8.6
                \]

                Note that, from the posterior distribution, we therefore have
                $\E(\Theta | x_1, ..., x_n) = \frac{4}{8.6} \approx 0.47 \approx
                \frac{1}{2}$, so the expectation is still pretty close to the
                prior distribution. However, when considering the variance,
                $\var(\Theta | x_1, ..., x_n) = \frac{4}{8.6^2} = 0.054 \ll
                \frac{1}{4}$, so the variance has greatly decreased.

                To find the posterior predictive pdf, we may use integration.
                For $x_{n+1} \geq 0$, we have:

                \begin{align*}
                    f(x_{n+1} | x_1, ..., x_n) = & \int_0^\infty f(x_{n+1} |
                        \theta) \cdot f(\theta | x_1, ..., x_n) d\theta \\
                    \propind{x_{n + 1}} & \int_0^\infty \theta \exp(-\theta
                        x_{n+1}) \theta^{\alpha_{n-1}} \exp(-\beta_n \theta)
                        d\theta \\
                    = & \int_0^\infty \theta^{\alpha_n} \exp(-(\beta_n +
                        x_{n+1})\theta) d\theta \\
                \end{align*}

                The integrand here is the pdf of a $\text{Gamma}(\alpha_{n} + 1,
                \beta_{n} + x_{n+1})$ distribution, up to some normalisation
                constant, so the integral is the Gamma function over such a
                constant:

                \begin{align*}
                    = & \frac{\Gamma(\alpha_n + 1)}{(\beta_n + x_{n+1})
                        ^{\alpha_n + 1}} \\
                    \propind{x_{n+1}} & (\beta_n + x_{n+1})^{-(\alpha_n + 1)}
                \end{align*}

                An alternative method for finding this result is to consider:

                \begin{align*}
                    f(x_{n+1} | x_1, ..., x_n) & = \frac{f(x_{n+1} | \theta)
                        f(\theta | x_1, ..., x_n)}{f(\theta | x_1, ...,
                        x_{n+1})} \\
                    & = \frac{\theta e^{-x_{n+1}\theta}\beta_n^{\alpha_n} /
                        \Gamma(\alpha_n) \cdot \theta^{\alpha_n - 1} e^{-\beta_n
                        \theta}}{\beta_{n+1}^{\alpha_{n+1}}/\Gamma(\alpha_{n+1})
                        \cdot \theta^{\alpha_{n+1} - 1} e^{-\beta_{n+1}\theta}}
                        \\
                    & = \frac{\Gamma(\alpha_n + 1)}{\Gamma(\alpha_n)} \cdot
                        \frac{\beta_n^{\alpha_n}}{(\beta_n + x_{n+1})^{\alpha_n
                        + 1}}
                \end{align*}

                This step is allowed because we have $\alpha_{n+1} = \alpha_n +
                1, \beta_{n+1} = \beta_n + x_{n+1}$.

                We then use a ``magical'' result that is left unproven for this
                course: the first term equals $\alpha_n$:

                \[
                    f(x_{n+1} | x_1, ..., x_n) = \frac{\alpha_n
                    \beta_n^{\alpha_n}}{(\beta_n + x_{n+1})^{\alpha_n + 1}}
                \]

                This is the same result.

                Note that the posterior predictive pdf found here is
                \textit{not} exponential! It follows the \textbf{Lomax
                Distribution}: $X_{n+1} | x_1, ..., x_n \sim
                \text{Lomax}(\alpha_n, \beta_n)$. For the Lomax distribution, we
                have:

                \begin{itemize}
                    \item $\E(X_{n+1} | x_1, ..., x_n) = \frac{\beta_n}{\alpha_n
                        - 1}$ if $\alpha_n > 1$
                    \item $\var(X_{n+1} | x_1, ..., x_n) = \frac{\beta_n^2
                        \alpha_n}{(\alpha_n - 1)^2(\alpha_n - 2)}$ if $\alpha >
                        2$
                \end{itemize}

                In our case, the posterior predictive pdf of $X_4$ is:

                \[
                    f(x_4 | x_1, x_2, x_3) \propind{x_4} (8.6 + x_4)^{-5}
                \]

                with:

                \[
                    \E(x_4 | x_1, ..., x_3) = \frac{8.6}{3} = 2.87
                \]
                \[
                    \var(x_4 | x_1, ..., x_3) = \frac{8.6^2 \cdot 4}{3^2 \cdot 2
                    } = 4.05^2
                \]

                \begin{fread}
                    [DS12, section 7.3] contains many more examples
                \end{fread}

                \begin{relq}
                    [DS12, section 7.3, exercises 1 - 13, 17, 19, 20]

                    Extra exercises: [DS12, section 7.3, exercises 14, 15, 16,
                    23, 24]
                \end{relq}

    \newpage
    \section{Bayes Estimators}
        \begin{fread}
            [DS12, section 7.4]
        \end{fread}

        Suppose that, instead of reporting the entire posterior distribution
        $f(\theta | x_1, ..., x_n)$, we we only want to report a summary (i.e: a
        single number, which is a function of the data such that this value is
        somehow ``close'' to the parameter $\Theta$). In other words, we want to
        find an \textit{estimator} for $\Theta$:

        \[
            \widehat \Theta := \delta(X_1, ..., X_n)
        \]

        We will find this based on the posterior distribution. We want to choose
        $\delta$ such that $\delta(X_1, ..., X_n) - \Theta$ is close to zero.

        We formally define this concept of ``distance'' with a loss function.

        \subsection{Loss Functions}
            \begin{definition}[Loss Function]
                A \textbf{loss function} $L(\theta, \widehat \theta)$ is just a
                real-valued function of two variables.

                The idea is that if $\Theta = \theta$ and we choose $\widehat
                \theta$ as our estimate, then we lose the amount $L(\theta,
                \widehat \theta)$. Typically, the larger the distance between
                $\theta$ and $\widehat \theta$, the larger the loss $L(\theta,
                \widehat \theta)$ will be.
            \end{definition}

            \subsubsection{Examples of Loss Functions}
                \begin{itemize}
                    \item \textbf{Squared Error Loss}

                        \[
                            L(\theta, \widehat \theta) := (\theta - \widehat
                            \theta)^2
                        \]

                    \item \textbf{Absolute Error Loss}

                        \[
                            L(\theta, \widehat \theta) := |\theta - \widehat
                            \theta|
                        \]

                    \item Arbitrary example
                        \[
                            L(\theta, \widehat \theta) := \begin{cases}3(
                            \widehat \theta - \theta)^2, & \theta \geq \widehat
                            \theta \\ (\widehat \theta - \theta)^2, &
                            \text{otherwise} \end{cases}
                        \]

                        Note that this is asymmetric, and could make sense if
                        underestimating is more costly than overestimating (e.g:
                        sea level rise).
                \end{itemize}

                We will mostly focus on squared error loss.

        \subsection{Bayes Estimator}
            If we have the posterior pdf $f(\theta | x_1, ..., x_n)$, then for
            any $\widehat \theta$, we can find the posterior expected loss.

            \begin{definition}[Posterior Expected Loss{,} Bayes Esimators and
                Estimates]
                The \textbf{posterior expected loss} is given by:

                \[
                    \E(L(\Theta, \widehat \theta) | x_1, ..., x_n) :=
                    \int_{-\infty}^\infty L(\theta, \widehat \theta) f(\theta |
                    x_1, ..., x_n) d\theta
                \]

                If working with a pmf, replace the integral with a sum.

                Let $L$ be any loss function. For any $x_1, ..., x_n$, let
                $\delta(x_1, ..., x_n)$ denote the value $\widehat \theta$ for
                which the posterior expected loss is minimised. Then
                $\delta(X_1, ..., X_n)$ is called the \textbf{Bayes Estimator}
                of $\Theta$, an $\delta(x_1, ..., x_n)$ is called the
                \textbf{Bayes Estimate} of $\widehat \Theta$.
            \end{definition}

            In other words, $\delta$ is chosen such that:

            \[
                \E(L(\Theta, \delta(x_1, ..., x_n)) | x_1, ..., x_n) =
                \min \E(L(\Theta, \widehat\Theta) | x_1, ..., x_n)
            \]

            Note that $\delta$ depends on:

            \begin{itemize}
                \item The data, $x_1, ..., x_n$
                \item The posterior distribution of $\Theta$
                \item The loss function $L$
            \end{itemize}

            \subsubsection{Theorem: Bayes Estimate in Squared Error Loss}
                Under squared error loss, the Bayes estimate for $\Theta$ is the
                posterior expectation for $\Theta$, given by:

                \[
                    \delta(x_1, ..., x_n) = \E(\Theta | x_1, ..., x_n)
                \]

                \paragraph{Proof}
                    For simplicity of exposition, we will omit the conditioning
                    on $x_1, ..., x_n$.

                    We need to show $\E((\Theta - \widehat \theta)^2)$ is
                    minimised for $\widehat \theta = \E(\Theta)$. Indeed:

                    \begin{align*}
                        \E((\Theta - \widehat \theta)^2) & = \E((\Theta -
                            \E(\Theta) + \E(\Theta) - \widehat \theta)^2) \\
                        & = \E((\Theta - \E(\Theta))^2) + 2\E(\Theta -
                            \E(\Theta))(\E(\Theta) - \widehat \theta) +
                            (\E(\Theta - \widehat \theta)^2)
                    \end{align*}

            \subsubsection{Example}
                Consider $X_i | \theta \sim \text{Bernoulli}$ IID conditional on
                $\Theta$, with prior $\Theta \sim \text{Beta}(\alpha, \beta)$.

                By conjugacy, we have the posterior $\Theta | x_1, ..., x_n \sim
                \text{Beta}(\alpha_n, \beta_n)$ with $\alpha_n := \alpha_0 +
                \sum\limits_{i=1}^n x_i, \beta_n := \beta_0 + n -
                \sum\limits_{i=1}^n x_i$.

                So the Bayes estimate under squared error loss is:

                \[
                    \E(\Theta | x_1, ..., x_n) = \frac{\alpha_n}{\alpha_n +
                    \beta_n} = \frac{\alpha_0 + \sum\limits_{i=1}^n x_i}
                    {\alpha_0 + \beta_0 + n}
                \]

                by the expression of the expectation of the beta distribution.
                The Bayes estimator for $\Theta$ is:

                \[
                    \widehat \Theta := \frac{\alpha_0 + \sum\limits_{i=1}^n X_i}
                    {\alpha_0 + \beta_0 + n}
                \]

                For instance, in our depression relapse problem, we had
                $\alpha_0 = \beta_0 = 1, n = 40, \sum\limits_{i=1}^n x_i = 22$,
                so $\widehat \theta = 23/42 = 0.55$ is our Bayes estimate.

            \subsubsection{Theorem: Bayes Estimate in Absolute Error Loss}
                Under absolute error loss, the Bayes estimate for $\Theta$ is
                the posterior median of $\Theta$, i.e: $\delta(x_1, ..., x_n)$
                is chosen such that:

                \[
                    \bb{P}(\Theta \leq \delta(x_1, ..., x_n) | x_1, ..., x_n) =
                    \frac{1}{2}
                \]

                \paragraph{Proof}
                    \begin{fread}
                        [DS12, theorem 4.5.3]
                    \end{fread}

    \newpage
    \section{Maximum Likelihood Estimators}
        \subsection{Definitions}
        As discussed previously, the \textbf{likelihood} is the pmf or pdf of
        the data, given the parameter, written as follows via conditional
        independence:

        \[
            f(x_1, ..., x_n | \theta) = \prod_{i=1}^n f(x_i | \theta)
            (=l(\theta))
        \]

        Bayes' theorem gives us that the posterior is proportional to the
        likelihood multiplied by the prior. But what do we do if we don't have a
        prior? This problem is what we'll consider today.

        \begin{definition}[Arg max{,} maximum likelihood estimator]
            For any function $g(\theta)$, let $\argmax{\theta} g(\theta)$ denote
            the value of $\theta$ for which $g(\theta)$ is maximised.

            $\theta* = \argmax{\theta} g(\theta)$ when $g(\theta*) = \max_\theta
            g(\theta)$.

            We define the \textbf{maximum likelihood estimator} (MLE) of
            $\Theta$ to be:

            \[
                \widehat \Theta = \delta(X_1, ..., X_n) = \argmax{\theta} f(X_1,
                ..., X_n | \theta)
            \]

            After observing $X_1 = x_1, ..., X_n = x_n$, then:

            \[
                \widehat \theta = \delta(x_1, ..., x_n) = \argmax{\theta} f(x_1,
                ..., x_n | \theta)
            \]

            is the \textbf{maximum likelihood estimate}.
        \end{definition}

        The interpretation of this is that $\widehat \theta$ is the value which
        maximises the probability of the data conditional on $\theta$.

        \subsection{Log Likelihood}
            In practice, we often work with the \textbf{log likelihood}, given
            by:

            \[
                L(\theta) := \log f(x_1, ..., x_n | \theta) = \sum_{i = 1}^n
                \log f(x_i | \theta)
            \]

            and then maximise $L(\theta)$ instead. Since $\log$ is a strictly
            increasing function, this is equivalent to maximising $l(\theta)$.

            How do we maximise such a function? We need to find $\widehat
            \theta$ such that $L'(\widehat \theta) = 0$ and $L''(\widehat
            \theta) < 0$.

            \subsubsection{Log Likelihood in Component Lifetimes Example}
                We have $X_i | \theta \sim \text{Exp}(\theta), \theta > 0$, with
                the observations $X_1 = 3, X_2 = 1.5, X_3 = 2.1$, and $X_i$ IID
                conditional on $\theta$.

                We therefore have the likelihood:

                \begin{align*}
                    f(x_1, ..., x_3 | \theta) & = \prod_{i=1}^3 \theta e^{
                        -\theta x} \\
                    & = \theta^3 e^{-\theta \sum\limits_{i=1}^3 x_i} \\
                    & = \theta^3 e^{-6.6\theta}
                \end{align*}

                And the log likelihood:

                \[
                    L(\theta) = 3\log\theta - 6.6\theta
                \]

                We wish to maximise this.

                \[
                    L'(\theta) = \frac{3}{\theta} - 6.6, \quad L''(\theta) = -
                    \frac{3}{\theta^2}
                \]

                At $\theta = \widehat \theta$, we have $L'(\widehat \theta) = 0
                \iff \widehat \theta = 0.455$. It's clear that $L''(\theta) < 0
                \fa \theta$, so the MLE is $\widehat \theta = 0.455$.

        \subsection{Bernoulli Sampling}
            Let's say we have $X_i \in \{0, 1\}, X_i | \theta \sim
            \text{Bernoulli}(\theta)$, so $\bb{P}(X_i = 1 | \theta) = \theta,
            \bb{P}(X_i = 0 | \theta) = 1 - \theta$.

            Therefore, the likelihood is:

            \begin{align*}
                f(x_1, x_n | \theta) & = \prod_{i=1}^n \theta^{x_i} (1 - \theta)
                    ^{1-x_i} \\
                & = \theta^{\sum x_i} \cdot (1 - \theta)^{n - \sum x_i}
            \end{align*}

            So $f(x_1, ..., x_n | \theta) = \theta^y (1 - \theta)^{n - y}$ where
            $y = \sum\limits_{i=1}^n x_i$, and we have the log likelihood:

            \[
                L(\theta) = y\log{\theta} + (n - y)\log(1 - \theta)
            \]

            To find the maximum, first consider the boundary cases:

            \begin{itemize}
                \item For $y = 0$, it's clear that $L(\theta)$ is monotone
                    decreasing in $\theta$, so the maximum is at $\widehat
                    \theta = 0$
                \item For $y = n$, we have that $L(\theta)$ is monotone
                    increasing in $\theta$, so $\widehat \theta = 1$
            \end{itemize}

            Otherwise, differentiate:

            \[
                L'(\theta) = \frac{y}{\theta} - \frac{n - y}{1 - \theta}
            \]

            At $\theta = \widehat \theta$:

            \begin{align*}
                & \frac{y}{\widehat \theta} - \frac{n - y}{1 - \widehat \theta}
                    = 0 \\
                \iff & y(1 - \widehat \theta) - (n - y)\widehat \theta) = 0 \\
                \implies & n\widehat \theta = y \\
                \implies & \widehat \theta = \frac{y}{n}
            \end{align*}

            This makes sense, since it's the sample proportion. We should also
            check that $L''(\widehat \theta) < 0$, but we won't bother here.

            So, the MLE $\widehat \theta = \frac{\sum\limits_{i=1}^n x_i}{n}$.

            Let's now compare this with the Bayes estimator under squared error
            loss, with prior $\Theta \sim \text{Beta}(\alpha_0, \beta_0)$, which
            will be the posterior expectation:

            \[
                \E(\theta | x_1, ..., x_n) = \frac{\alpha_0 +
                \sum\limits_{i=1}^n x_i}{\alpha_0 + \beta_0 + n}
            \]

            This Bayesian estimate will tend to the MLE $\widehat \theta$ as
            $\alpha_0 \to 0, \beta_0 \to 0$.

    \newpage
    \section*{Problems Classes}
    \addcontentsline{toc}{section}{\protect\numberline{}Problems Classes}
        \subsection*{07-Feb-2020}
        \addcontentsline{toc}{subsection}{\protect\numberline{}07-Feb-2020}
            \paragraph{11}
            \textit{$n = 100$ random samples of water from a fresh water lake
            were taken and the calcium concentration (given in milligrams per
            litre) measured. A 95\% confidence interval on the mean calcium
            concentration $\Theta$ is $[0.49, 0.82]$, where the standard
            deviation is assumed to be known}

            \textit{(a) Consider the following statement: There is a 95\% chance
            that $\Theta$ is between 0.49 and 0.82. Is this statement correct?
            Explain your answer}

                No, the statement is not correct, as the confidence interval is
                conditioned on $\theta$, so we are making a probability
                statement about the \textit{data}, not the parameter!

                \[
                    \bb{P}(\bar X_n - 1.96 \frac{\sigma}{\sqrt{n}} \leq \theta
                    \leq \bar X_n + 1.96 \frac{\sigma}{\sqrt{n}}) = 0.95
                \]

                From the information we know, the probability $\bb{P}(0.49 \leq
                \Theta \leq 0.82)$ could be anywhere between 0 and 1, and
                actually depends on the prior.

                Also, $\bb{P}(0.49 \leq \theta \leq 0.82 | \theta)$ will be
                either 0 or 1 depending on $\theta$.

            \textit{(b) The process of taking $n = 100$ random samples of water
            from the lake and computing a 95\% confidence interval on $\Theta$
            is repeated 1000 times, each time obtaining a slightly different
            interval due to randomness across the different samples. One of
            these intervals is $[0.49, 0.82]$. The true value $\theta$ of
            $\Theta$ is then revealed. Someone claims that precisely 950 of the
            1000 95\% confidence intervals computed earlier should contain
            $\theta$. Is this correct? Explain your answer.}

                This is \textit{not} correct, although we could say that it's
                ``almost'' correct. We need to remember that, ultimately, the
                number of intervals that will contain $\theta, Y,$ is a random
                variable, and is not known in advance. $Y$ may be thought of as
                a sum of Bernoulli variables:

                \[
                    Y = \sum_{i=1}^{1000} I_{A_i}, \quad A_i =\{\overline
                    X_{n,i} - 1.96 \frac{\sigma}{\sqrt{n}} \leq \Theta \leq ...
                    + 1.96 ... \}
                \]

                If conditional on $\Theta = \theta, Y$ will still not have a
                fixed value! Recall:

                \[
                    I_{A_i}(\omega) := \begin{cases}1, & \omega \in A_i \\ 0, &
                    \omega \not \in A_i\end{cases}
                \]

                Note that $\bb{P}(A_i | \theta) = 0.95$.

            \textit{(c) Let $Y$ denote the number of 1000 95\% confidence
            intervals that contain $\Theta$. Identify the unconditional
            distribution of $Y$, and compute its unconditional mean and standard
            deviation. Finally, identify two numbers $a, b$ such that
            (approximately) $\bb{P}(a \leq Y \leq b) = 0.95$.}

                By (b), we have:

                \[
                    Y | \theta \sim \text{Bin}(1000, 0.95)
                \]

                Because this conditional distribution doesn't depend on
                $\Theta$, by the partition theorem, we have:

                \[
                    p(y) = \int_0^1 p(y | \theta) f(\theta) d\theta =
                    p(y | \theta)
                \]

                Note that $p(y | \theta)$ doesn't depend on $\theta$, so we have

                \[
                    p(y) = p(y | \theta) \int_0^1 f(\theta) d\theta
                \]

                So, $Y \sim \text{Bin}(1000, 0.95)$.

                Note that $\E(Y) = 1000 \cdot 0.95 = 950, \var(Y) = 1000 \cdot
                0.95 \cdot 0.05 = 6.89^2$.

                Since we have a large $n$, we may approximate the binomial
                distribution by the normal distribution, so approximately:

                \[
                    Y \sim \mathcal{N}(950, 6.89^2)
                \]

                Therefore, a 95\% interval on $Y$ can be calculated:

                \[
                    \bb{P}(950 - 1.96 \cdot 6.89 \leq Y \leq 950 + 1.96 \cdot
                    6.89) = 0.95
                \]
                \[
                    [936.5, 963.5]
                \]

            \paragraph{22}
            \textit{Consider again the conditions of exercise 21, and assume the
            same prior distribution of $\Theta$. Suppose now, however, that six
            observations are selected at random from the uniform distribution
            $[\theta - 1/2, \theta + 1/2]$, and their values are $11.0, 11.5,
            11.7, 11.1, 11.4, 10.3$. Determine the posterior distribution}.

                We have $X_i | \theta \sim \mathcal{U}(\theta - 1/2, \theta +
                1/2)$, and the prior $\Theta \sim \mathcal{U}(10, 20)$.

                \[
                    f(\theta | x_1, ..., x_n) \propind{\theta} f(\theta)
                    \prod_{i=1}^n f(x_i | \theta)
                \]

                where $f(\theta) \propind{\theta} \begin{cases}1, & \theta \in
                [10, 20] \\ 0, &\text{otherwise}\end{cases}$.

                \[
                    \implies f(x_i | \theta) = \begin{cases}1, & x_i \in [\theta
                    - 1/2, \theta + 1/2] \\ 0, & \text{otherwise}\end{cases}
                \]

                $x_i \in [\theta - 1/2, \theta + 1/2] \iff \theta \in [x_i -
                1/2, x_i + 1/2]$, so we have:

                \[
                    f(\theta | x_1, ..., x_n) \propind{\theta} \begin{cases}1, &
                    \theta \in [10, 20] \land \theta \in [x_i - 1/2, x_i + 1/2]
                    \,\fa i = 1, ..., n \\ 0, & \text{otherwise}\end{cases}
                \]

                The first condition of this piecewise function holds $\iff
                \theta \in [10, 20] \cap \bigcap\limits_{i=1}^n [x_i - 1/2, x_i
                + 1/2] \iff \theta \in [10] \cap [\max\limits_{i=1}^n x_i - 1/2,
                \min\limits_{i=1}^n x_i + 1/2]$. Let $x^* = \max\limits_{i=1}^n
                x_i, x_* = \min\limits_{i = 1}^n x_i$ So we have:

                \[
                    \Theta | x_1, ..., x_n \sim \mathcal{U}(x^* - 1/2, x_* +
                    1/2) = \mathcal{U}(11.2, 11.4)
                \]

            \paragraph{33}
            \textit{Let $\theta$ denote the average number of defects per 100
            feet of a certain type of magnetic tape. Suppose that the value of
            $\theta$ is unknown and that the prior distribution of $\Theta$ is
            the gamma distribution with parameters $\alpha_0 = 2, \beta_0 = 10$.
            When a 1200-foot roll of this tape is inspected, exactly four
            defects are found. Determine the posterior distribution of
            $\Theta$.}
                \begin{relq}
                    Consider exercise 31 first!
                \end{relq}

                We could pretend that instead of one 1200 foot roll, we instead
                have 12 one foot rolls, with a total of $\sum\limits_{i=1}^{12}
                x_i = 4$ defects. Therefore, by exercise 31, the posterior
                distribution is:

                \[
                    \text{Gamma}\left(\alpha_0 + \sum\limits_{i=1}^{n} x_i,
                    \beta_0 + n\right) = \text{Gamma}(3 + 4, 1 + 12) =
                    \text{Gamma}(7, 13)
                \]

\end{document}
